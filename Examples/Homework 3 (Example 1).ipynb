{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3\n",
    "\n",
    "Submit via Slack. Due on Tuesday, April 13th, 2020, 6:29pm PST. You may work with one other person.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "You are an analyst working at McDonalds as a store operations analyst, and charged with identifying areas for improvement for each franchise. Several metropolitan locations have been suffering recently from lower reviews.\n",
    "\n",
    "Using the **mcdonalds-yelp-negative-reviews.csv** dataset, clean and parse the text reviews. Explain the decisions you make:\n",
    "- why remove/keep stopwords?\n",
    "- which stopwords to remove?\n",
    "- stemming versus lemmatization?\n",
    "- regex cleaning and substitution?\n",
    "- adding in custom stopwords?\n",
    "- what `n` for your `n-grams`?\n",
    "- which words to collocate together?\n",
    "\n",
    "Finally, generate a TF-IDF report that either **visualizes** or explains for a business (non-technical) stakeholder:\n",
    "* the features your analysis showed that customers cited as reasons for a poor review\n",
    "* the most common issues identified from your analysis that generated customer dissatisfaction.\n",
    "\n",
    "Explain to what degree the TF-IDF findings make sense - what are its limitations?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "#Read the reviews file\n",
    "mcd = pd.read_csv('/Users/maheshpandit/Documents/NLP/dso-560-nlp-text-analytics-SPRING-2021/Week 3/mcdonalds-yelp-negative-reviews.csv', encoding = 'latin1')\n",
    "\n",
    "mcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the different ways of saying \"McDonalds\" by a standard form\n",
    "mcd.review = mcd.review.str.replace(r\"(?:(?:M|m)a*(?:c|C)(?:d|D)(?:onald)*|(?:M|m)ickey (?:D|d)(?:ee)*|(?:G|g)olden (?:A|a)rche)'*(?:s|S)*\", \"McDonald's\")\n",
    "\n",
    "#Replace the different ways of saying \"drive-through\" by a standard form\n",
    "mcd.review = mcd.review.str.replace(r\"(?:D|d)rive(?:-)*\\s*(?:T|t)(?:hru|hrough)\", \"drive-through\")\n",
    "\n",
    "#Replace the different ways of saying \"take-out\" by a standard form\n",
    "mcd.review = mcd.review.str.replace(r\"(?:T|t)ake(?:-)*\\s*(?:O|o)ut\", \"take-out\")\n",
    "\n",
    "#Remove all punctuations\n",
    "mcd.review = mcd.review.str.replace(r\"[^\\w\\s]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stp = set(stopwords.words(\"english\")) #These are common English stopwords that do not add any value to our analysis\n",
    "stp = stp - {\"off\", \"over\", \"under\"} #Excluding these stopwords because they can be used to describe food. ex: over cooked, under cooked \n",
    "stp.add(\"mcdonald\") #Including McDonald's because it provides no value to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# https://gaurav5430.medium.com/using-nltk-for-lemmatizing-sentences-c1bfff963258\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen to use lemmatization here instead of stemming because it is important to understand the sentiment of the reviews when we are trying to determine the reasons. It is easier to determine the sentiment of the reviews when stemming is used since it takes the part of speech into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_reviews = [lemmatize_sentence(review) for review in mcd.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents = []\n",
    "doc_words = []\n",
    "for doc in lemmatized_reviews:\n",
    "    new_document = []\n",
    "    for word in doc:\n",
    "        if word.strip().lower() not in stp:\n",
    "            new_document.append(word)\n",
    "            doc_words.append(new_document)\n",
    "    new_documents.append(' '.join(new_document) )\n",
    "    \n",
    "mcd['cleaned_lemmatized_reviews'] = new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for i in range(2, 5):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(i,i))\n",
    "    corpus = new_documents\n",
    "\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "    tf_idf = tf_idf.sum(axis=1)\n",
    "    score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "    score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "    print(\"These are the 20 most common n-grams of size %d\"%i)\n",
    "    print(\"{}\\n\".format(score.head(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the most common reasons for a poor review, I have looked at the top 20 TF-IDF scores for n-grams of range 2, 3 and 4. I believe that this is a reasonable range that covers issues with a single product or service, as well as systemic issues. The reason I have not used the range(2, 5) within a single vectorizer is because some important n-grams of bigger size may have a relatively lower score when compared to less-important n-grams of the same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the TF-IDF scores above, it is clear that some of the most common issues are:\n",
    "\n",
    "- bad customer service\n",
    "- issues with ice cream\n",
    "- getting orders wrong\n",
    "- long wait times\n",
    "\n",
    "Let us take a closer look at these issues individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd['customer_service_issue'] = mcd['cleaned_lemmatized_reviews'].str.contains(r'customer service|rude', regex = True, case = False )\n",
    "\n",
    "mcd['ice_cream_issue'] = mcd['cleaned_lemmatized_reviews'].str.contains(r'ice cream', regex = True, case = False )\n",
    "\n",
    "mcd['wrong_order_issue'] = mcd['cleaned_lemmatized_reviews'].str.contains(r'order right|order wrong|order correct', regex = True, case = False )\n",
    "\n",
    "mcd['wait_time_issue'] = mcd['cleaned_lemmatized_reviews'].str.contains(r'wait long|long wait|slow', regex = True, case = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mcd['customer_service_issue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd['ice_cream_issue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mcd['wrong_order_issue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd['wait_time_issue'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of bad customer service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mcd[ mcd['customer_service_issue'] == True ][\"review\"].head(30):\n",
    "    print(\"{}\\n\\n\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cs_issues = mcd[ mcd['customer_service_issue'] == True ]['cleaned_lemmatized_reviews'].str.replace(\"customer service\", \"\", case = False).values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3) )\n",
    "corpus = cs_issues\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"These are the 5 highest tf-idf scores for customer-service issue n-grams of size 3\")\n",
    "print(\"{}\\n\".format(score.head(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis of the reviews that complained about bad customer service, the most common issues that were identified are:\n",
    "\n",
    "- employees are rude to customers\n",
    "- orders are not fulfilled correctly very often\n",
    "- employees are sometimes busy using the cash register and do not acknowledge customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of ice cream issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in mcd[ mcd['ice_cream_issue'] == True ][\"review\"].head(30):\n",
    "    print(\"{}\\n\\n\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the reviews, it is evident that some of the common issues with ice cream are:\n",
    "\n",
    "- ice cream machine is broken/locked\n",
    "- ice cream is not served after a certain time\n",
    "- they have run out of ice cream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of wrong orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in mcd[ mcd['wrong_order_issue'] == True ][\"review\"].head(30):\n",
    "    print(\"{}\\n\\n\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wo_issues = mcd[ mcd['wrong_order_issue'] == True ]['cleaned_lemmatized_reviews'].str.replace(r'(?:get)*\\sorder\\sright|(?:get)*\\sorder\\swrong', \"\", regex = True).values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,4) )\n",
    "corpus = wo_issues\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"These are the 20 highest tf-idf scores for wrong order issue n-grams of sizes 2 and 3\")\n",
    "print(\"{}\\n\".format(score.head(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis of the issue of getting orders wrong, it seems like this problem is prevalent in drive-throughs as well as dine-in. There does not seem to be a specific reason for this other than human error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of long wait times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mcd[ mcd['wait_time_issue'] == True ][\"review\"].head(30):\n",
    "    print(\"{}\\n\\n\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt_issues = mcd[ mcd['wait_time_issue'] == True ]['cleaned_lemmatized_reviews'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3) )\n",
    "corpus = wt_issues\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "print(\"These are the 10 highest tf-idf scores for wrong order issue n-grams of size 3\")\n",
    "print(\"{}\\n\".format(score.head(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis of the reviews about long wait times, it seems that the majority of these issues are occuring in drive throughs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues with TF-IDF\n",
    "\n",
    "The TF-IDF methodology helps us identify n-grams that are uniquely important to multiple documents in the corpus. However, there are some limitations:\n",
    "\n",
    "- It is essentially a bag-of-words methodology since it does not take into account the semantics of the words. This results in different n-grams with high scores, but the same meaning. For example, \"never get order right\" and \"always get order wrong\".\n",
    "\n",
    "- Some n-grams with high TF-IDF score do not offer any value to our analysis because they do not make sense. For example, \"hey cup coffee drive\"\n",
    "\n",
    "- Some n-grams with high scores are just phrases that are oftern used together in English. For example, \"24 hour drive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Attribution (Feature Engineering and Regex Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [dataset](https://dso-560-nlp-text-analytics.s3.amazonaws.com/truncated_catalog.csv) from the class S3 bucket (`dso560-nlp-text-analytics`).\n",
    "\n",
    "In preparation for the group project, our client company has provided a dataset of women's clothing products they are considering cataloging. \n",
    "\n",
    "1. Filter for only **women's clothing items**.\n",
    "\n",
    "2. For each clothing item:\n",
    "\n",
    "* Identify its **category**:\n",
    "```\n",
    "Bottom\n",
    "One Piece\n",
    "Shoe\n",
    "Handbag\n",
    "Scarf\n",
    "```\n",
    "* Identify its **color**:\n",
    "```\n",
    "Beige\n",
    "Black\n",
    "Blue\n",
    "Brown\n",
    "Burgundy\n",
    "Gold\n",
    "Gray\n",
    "Green\n",
    "Multi \n",
    "Navy\n",
    "Neutral\n",
    "Orange\n",
    "Pinks\n",
    "Purple\n",
    "Red\n",
    "Silver\n",
    "Teal\n",
    "White\n",
    "Yellow\n",
    "```\n",
    "\n",
    "Your output will be the same dataset, except with **3 additional fields**:\n",
    "* `is_womens_clothing`\n",
    "* `product_category`\n",
    "* `colors`\n",
    "\n",
    "`colors` should be a list of colors, since it is possible for a piece of clothing to have multiple colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv('truncated_catalog.csv')\n",
    "catalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def isWomensClothing(txt):\n",
    "    \"\"\" Function to determine whether it is an article of women's clothing \"\"\"\n",
    "    \n",
    "    txt = str(txt)\n",
    "    val = False\n",
    "    if re.search(r'girl|wom(?:an|en)|lad(?:y|ies)', txt, re.IGNORECASE ):\n",
    "        val = True\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['is_womens_clothing'] = pd.DataFrame( [ catalog.name.apply( isWomensClothing ), catalog.description.apply( isWomensClothing ), catalog.brand_category.apply( isWomensClothing ) ] ).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCategory(txt):\n",
    "    \"\"\" Function to determine the article of clothing \"\"\"\n",
    "    \n",
    "    txt = str(txt)\n",
    "    val = np.nan\n",
    "    if re.search(r'pants|trousers|jeans|shorts|leggings|skirt|jumpsuit', txt, re.IGNORECASE ):\n",
    "        val = \"Bottom\"\n",
    "    elif re.search(r'\\bdress\\b|gown|jumpsuit', txt, re.IGNORECASE ):\n",
    "        val = \"One Piece\"\n",
    "    elif re.search(r'shoes|sneakers|heels|pumps', txt, re.IGNORECASE ):\n",
    "        val = \"Shoe\"\n",
    "    elif re.search(r'purse|handbag|tote|clutch', txt, re.IGNORECASE ):\n",
    "        val = \"Handbag\"\n",
    "    elif re.search(r'scar(?:f|ves)|bandana', txt, re.IGNORECASE ):\n",
    "        val = \"Scarf\"\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog[\"product_category\"] = catalog.description.apply( findCategory ).combine_first( catalog.details.apply( findCategory ).combine_first( catalog.brand_category.apply( findCategory ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_re = r'\\bBeige\\b|\\bBlack\\b|\\bBlue\\b|\\bBrown\\b|\\bBurgundy\\b|\\bGold\\b|\\bGray\\b|\\bGreen\\b|\\bMulticolor|\\bNavy\\b|\\bNeutral\\b|\\bOrange\\b|\\bPinks\\b|\\bPurple\\b|\\bRed\\b|\\bSilver\\b|\\bTeal\\b|\\bWhite\\b|\\bYellow\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findColors(txt):\n",
    "    \"\"\" Function to determine the color of item \"\"\"\n",
    "    \n",
    "    val = []\n",
    "    txt = str(txt)\n",
    "    if re.findall(colors_re, txt, re.IGNORECASE ):\n",
    "        val = re.findall(colors_re, txt, re.IGNORECASE )\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['colors'] = catalog.description.apply(findColors) + catalog.details.apply(findColors) + catalog.tsv.apply(findColors)\n",
    "catalog.colors = catalog.colors.apply(lambda x: set(y.lower() for y in x))\n",
    "catalog.colors = catalog.colors.replace(set(), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
