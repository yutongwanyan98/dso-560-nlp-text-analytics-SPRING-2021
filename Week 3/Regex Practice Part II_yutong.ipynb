{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Dependencies-and-Load-in-Dataset\" data-toc-modified-id=\"Import-Dependencies-and-Load-in-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Dependencies and Load in Dataset</a></span></li><li><span><a href=\"#Pandas-Exploratory-Data-Analysis\" data-toc-modified-id=\"Pandas-Exploratory-Data-Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pandas Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Show-the-First/Last-Rows-of-Dataset\" data-toc-modified-id=\"Show-the-First/Last-Rows-of-Dataset-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Show the First/Last Rows of Dataset</a></span></li><li><span><a href=\"#Drop-Unnecessary-Pandas-Column\" data-toc-modified-id=\"Drop-Unnecessary-Pandas-Column-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Drop Unnecessary Pandas Column</a></span></li><li><span><a href=\"#Compute-a-New-Pandas-Series-and-Attach-to-Dataframe-as-Column\" data-toc-modified-id=\"Compute-a-New-Pandas-Series-and-Attach-to-Dataframe-as-Column-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Compute a New Pandas Series and Attach to Dataframe as Column</a></span></li><li><span><a href=\"#Count-Number-of-Rows-in-Dataframe-Meet-Some-Criteria\" data-toc-modified-id=\"Count-Number-of-Rows-in-Dataframe-Meet-Some-Criteria-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>Count Number of Rows in Dataframe Meet Some Criteria</a></span></li><li><span><a href=\"#Filter-DataFrame-for-a-Subset-of-Rows\" data-toc-modified-id=\"Filter-DataFrame-for-a-Subset-of-Rows-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>Filter DataFrame for a Subset of Rows</a></span></li></ul></li><li><span><a href=\"#Difference-Between-extractall-and-findall\" data-toc-modified-id=\"Difference-Between-extractall-and-findall-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Difference Between <code>extractall</code> and <code>findall</code></a></span></li></ul></li><li><span><a href=\"#Regex-Character-Classes\" data-toc-modified-id=\"Regex-Character-Classes-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Regex Character Classes</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Find-all-Tweets-That-Start-with-a-Number\" data-toc-modified-id=\"Find-all-Tweets-That-Start-with-a-Number-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Find all Tweets That Start with a Number</a></span></li><li><span><a href=\"#Find-all-@-Mentions\" data-toc-modified-id=\"Find-all-@-Mentions-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Find all @ Mentions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Alternative-Method-to-Work-With-Lists-in-Pandas\" data-toc-modified-id=\"Alternative-Method-to-Work-With-Lists-in-Pandas-3.0.2.1\"><span class=\"toc-item-num\">3.0.2.1&nbsp;&nbsp;</span>Alternative Method to Work With Lists in Pandas</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Quantifiers\" data-toc-modified-id=\"Quantifiers-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Quantifiers</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Match-All-Phone-Numbers-(Link)\" data-toc-modified-id=\"Match-All-Phone-Numbers-(Link)-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Match All Phone Numbers (<a href=\"https://regexr.com/50v17\" target=\"_blank\">Link</a>)</a></span></li><li><span><a href=\"#Parse-Out-Zip-Codes-(Link)\" data-toc-modified-id=\"Parse-Out-Zip-Codes-(Link)-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Parse Out Zip Codes (<a href=\"https://regexr.com/50v1g\" target=\"_blank\">Link</a>)</a></span></li></ul></li></ul></li><li><span><a href=\"#Capture-Groups\" data-toc-modified-id=\"Capture-Groups-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Capture Groups</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Example:-Parsing-out-Weekday-from-Timestamp-String-(Link)\" data-toc-modified-id=\"Example:-Parsing-out-Weekday-from-Timestamp-String-(Link)-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>Example: Parsing out Weekday from Timestamp String (<a href=\"https://regexr.com/50v0l\" target=\"_blank\">Link</a>)</a></span></li><li><span><a href=\"#Example:-Parsing-Out-Domain-Names\" data-toc-modified-id=\"Example:-Parsing-Out-Domain-Names-5.0.2\"><span class=\"toc-item-num\">5.0.2&nbsp;&nbsp;</span>Example: Parsing Out Domain Names</a></span></li></ul></li><li><span><a href=\"#Non-Capture-Groups\" data-toc-modified-id=\"Non-Capture-Groups-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Non-Capture Groups</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-1-(Link)\" data-toc-modified-id=\"Example-1-(Link)-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Example 1 <a href=\"https://regexr.com/50t7c\" target=\"_blank\">(Link)</a></a></span></li><li><span><a href=\"#Example-2-(Link)\" data-toc-modified-id=\"Example-2-(Link)-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Example 2 <a href=\"https://regexr.com/50t7c\" target=\"_blank\">(Link)</a></a></span></li><li><span><a href=\"#Example-3-(Link)\" data-toc-modified-id=\"Example-3-(Link)-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Example 3 (<a href=\"https://regexr.com/50ush\" target=\"_blank\">Link</a>)</a></span></li></ul></li></ul></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Exercises</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Find-the-subject-headings-for-these-emails.\" data-toc-modified-id=\"Find-the-subject-headings-for-these-emails.-6.0.0.1\"><span class=\"toc-item-num\">6.0.0.1&nbsp;&nbsp;</span>Find the subject headings for these emails.</a></span></li><li><span><a href=\"#Find-all-hashtags-mentioned-in-the-tweets_df-dataset.-Store-it-as-a-separate-column-called-hashtags.\" data-toc-modified-id=\"Find-all-hashtags-mentioned-in-the-tweets_df-dataset.-Store-it-as-a-separate-column-called-hashtags.-6.0.0.2\"><span class=\"toc-item-num\">6.0.0.2&nbsp;&nbsp;</span>Find all hashtags mentioned in the <code>tweets_df</code> dataset. Store it as a separate column called <strong>hashtags</strong>.</a></span></li><li><span><a href=\"#In-fraudulent_emails.txt,-identify-the-list-of-email-addresses-for-your-security-administrator-to-blacklist-from-your-company's-email-servers.\" data-toc-modified-id=\"In-fraudulent_emails.txt,-identify-the-list-of-email-addresses-for-your-security-administrator-to-blacklist-from-your-company's-email-servers.-6.0.0.3\"><span class=\"toc-item-num\">6.0.0.3&nbsp;&nbsp;</span>In <code>fraudulent_emails.txt</code>, identify the <strong>list of email addresses</strong> for your security administrator to blacklist from your company's email servers.</a></span></li><li><span><a href=\"#In-fraudulent_emails.txt,-identify-any-IP-addresses-that-should-be-blacklisted\" data-toc-modified-id=\"In-fraudulent_emails.txt,-identify-any-IP-addresses-that-should-be-blacklisted-6.0.0.4\"><span class=\"toc-item-num\">6.0.0.4&nbsp;&nbsp;</span>In <code>fraudulent_emails.txt</code>, identify any IP addresses that should be blacklisted</a></span></li><li><span><a href=\"#The-word-&quot;AT&amp;T&quot;-is-not-spelled-correctly-in-the-tweets_df-dataset.-Correct-the-misspelling.\" data-toc-modified-id=\"The-word-&quot;AT&amp;T&quot;-is-not-spelled-correctly-in-the-tweets_df-dataset.-Correct-the-misspelling.-6.0.0.5\"><span class=\"toc-item-num\">6.0.0.5&nbsp;&nbsp;</span>The word \"AT&amp;T\" is not spelled correctly in the <code>tweets_df</code> dataset. Correct the misspelling.</a></span></li><li><span><a href=\"#Removing-hashtags-and-mentions,-which-topic-has-the-highest-average-tweet-character-count?\" data-toc-modified-id=\"Removing-hashtags-and-mentions,-which-topic-has-the-highest-average-tweet-character-count?-6.0.0.6\"><span class=\"toc-item-num\">6.0.0.6&nbsp;&nbsp;</span>Removing hashtags and mentions, which topic has the highest average tweet character count?</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies and Load in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets_df: pd.DataFrame = pd.read_csv(\"tweets_pandas.csv\")\n",
    "#tweets_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the First/Last Rows of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   likes  index                          date    topic    handle  \\\n",
       "0      4      3  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
       "1      4      4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
       "2      4      5  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
       "3      4      6  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
       "4      4      7  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
       "\n",
       "                                               tweet  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>likes</th>\n      <th>index</th>\n      <th>date</th>\n      <th>topic</th>\n      <th>handle</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>3</td>\n      <td>Mon May 11 03:17:40 UTC 2009</td>\n      <td>kindle2</td>\n      <td>tpryan</td>\n      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>4</td>\n      <td>Mon May 11 03:18:03 UTC 2009</td>\n      <td>kindle2</td>\n      <td>vcu451</td>\n      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>5</td>\n      <td>Mon May 11 03:18:54 UTC 2009</td>\n      <td>kindle2</td>\n      <td>chadfu</td>\n      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>6</td>\n      <td>Mon May 11 03:19:04 UTC 2009</td>\n      <td>kindle2</td>\n      <td>SIX15</td>\n      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>7</td>\n      <td>Mon May 11 03:21:41 UTC 2009</td>\n      <td>kindle2</td>\n      <td>yamarama</td>\n      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     likes  index                          date  topic           handle  \\\n",
       "493      2  14072  Sun Jun 14 04:31:43 UTC 2009  latex          proggit   \n",
       "494      0  14073  Sun Jun 14 04:32:17 UTC 2009  latex           sam33r   \n",
       "495      4  14074  Sun Jun 14 04:36:34 UTC 2009  latex  iamtheonlyjosie   \n",
       "496      0  14075  Sun Jun 14 21:36:07 UTC 2009   iran        plutopup7   \n",
       "497      0  14076  Sun Jun 14 21:36:17 UTC 2009   iran     captain_pete   \n",
       "\n",
       "                                                 tweet  \n",
       "493  Ask Programming: LaTeX or InDesign?: submitted...  \n",
       "494  On that note, I hate Word. I hate Pages. I hat...  \n",
       "495  Ahhh... back in a *real* text editing environm...  \n",
       "496  Trouble in Iran, I see. Hmm. Iran. Iran so far...  \n",
       "497  Reading the tweets coming out of Iran... The w...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>likes</th>\n      <th>index</th>\n      <th>date</th>\n      <th>topic</th>\n      <th>handle</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>493</th>\n      <td>2</td>\n      <td>14072</td>\n      <td>Sun Jun 14 04:31:43 UTC 2009</td>\n      <td>latex</td>\n      <td>proggit</td>\n      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>0</td>\n      <td>14073</td>\n      <td>Sun Jun 14 04:32:17 UTC 2009</td>\n      <td>latex</td>\n      <td>sam33r</td>\n      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>4</td>\n      <td>14074</td>\n      <td>Sun Jun 14 04:36:34 UTC 2009</td>\n      <td>latex</td>\n      <td>iamtheonlyjosie</td>\n      <td>Ahhh... back in a *real* text editing environm...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0</td>\n      <td>14075</td>\n      <td>Sun Jun 14 21:36:07 UTC 2009</td>\n      <td>iran</td>\n      <td>plutopup7</td>\n      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>0</td>\n      <td>14076</td>\n      <td>Sun Jun 14 21:36:17 UTC 2009</td>\n      <td>iran</td>\n      <td>captain_pete</td>\n      <td>Reading the tweets coming out of Iran... The w...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tweets_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Pandas Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.drop(columns=['index'])\n",
    "# or tweets_df.drop(columns=['index'], inplace = True), more efficient and one less variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a New Pandas Series and Attach to Dataframe as Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of tweets in characters\n",
    "\n",
    "tweets_df['tweet_length'] = tweets_df.tweet.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Number of Rows in Dataframe Meet Some Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     likes                          date        topic           handle  \\\n",
       "9        4  Mon May 11 03:29:20 UTC 2009        obama      mandanicole   \n",
       "10       2  Mon May 11 03:32:42 UTC 2009        obama             jpeb   \n",
       "11       0  Mon May 11 03:32:48 UTC 2009        obama      kylesellers   \n",
       "12       4  Mon May 11 03:33:38 UTC 2009        obama      theviewfans   \n",
       "48       0  Sun May 17 17:32:00 UTC 2009          aig     KennyTRoland   \n",
       "102      0  Mon May 25 17:35:23 UTC 2009       cheney           jepaco   \n",
       "243      4  Mon May 11 03:29:01 UTC 2009        obama     lingbellbell   \n",
       "244      4  Mon May 11 03:29:38 UTC 2009        obama        motsandco   \n",
       "245      4  Mon May 11 03:29:41 UTC 2009        obama           mickou   \n",
       "246      4  Mon May 11 03:32:35 UTC 2009        obama       meggentile   \n",
       "247      4  Mon May 11 03:33:05 UTC 2009        obama         failness   \n",
       "248      4  Mon May 11 03:33:43 UTC 2009        obama            kledy   \n",
       "249      4  Mon May 11 03:34:04 UTC 2009        obama  LaurelEdelstein   \n",
       "330      0  Mon May 25 17:19:30 UTC 2009  north korea            Mvsic   \n",
       "331      0  Mon May 25 17:21:16 UTC 2009       pelosi        CFURNAROS   \n",
       "375      2  Tue Jun 02 03:00:51 UTC 2009           gm      economywire   \n",
       "\n",
       "                                                 tweet  tweet_length  \\\n",
       "9    how can you not love Obama? he makes jokes abo...            57   \n",
       "10   Check this video out -- President Obama at the...           101   \n",
       "11   @Karoli I firmly believe that Obama/Pelosi hav...           140   \n",
       "12   House Correspondents dinner was last night who...           106   \n",
       "48   ?Obama Administration Must Stop Bonuses to AIG...            85   \n",
       "102  Dick Cheney's dishonest speech about torture, ...           102   \n",
       "243  Obama is quite a good comedian! check out his ...            87   \n",
       "244  ' Barack Obama shows his funny side \" &gt;&gt;...            82   \n",
       "245  I like this guy : ' Barack Obama shows his fun...            85   \n",
       "246  Obama's speech was pretty awesome last night! ...            65   \n",
       "247  Reading  \"Bill Clinton Fail - Obama Win?\" http...            67   \n",
       "248  Obama More Popular Than U.S. Among Arabs: Surv...           140   \n",
       "249  Obama's got JOKES!! haha just got to watch a b...           128   \n",
       "330       Listening to Obama... Friggin North Korea...            44   \n",
       "331  I just realized we three monkeys in the white ...            83   \n",
       "375  Obama: Nationalization of GM to be short-term ...            78   \n",
       "\n",
       "     contains_obama  \n",
       "9              True  \n",
       "10             True  \n",
       "11             True  \n",
       "12             True  \n",
       "48             True  \n",
       "102            True  \n",
       "243            True  \n",
       "244            True  \n",
       "245            True  \n",
       "246            True  \n",
       "247            True  \n",
       "248            True  \n",
       "249            True  \n",
       "330            True  \n",
       "331            True  \n",
       "375            True  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>likes</th>\n      <th>date</th>\n      <th>topic</th>\n      <th>handle</th>\n      <th>tweet</th>\n      <th>tweet_length</th>\n      <th>contains_obama</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>Mon May 11 03:29:20 UTC 2009</td>\n      <td>obama</td>\n      <td>mandanicole</td>\n      <td>how can you not love Obama? he makes jokes abo...</td>\n      <td>57</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2</td>\n      <td>Mon May 11 03:32:42 UTC 2009</td>\n      <td>obama</td>\n      <td>jpeb</td>\n      <td>Check this video out -- President Obama at the...</td>\n      <td>101</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>Mon May 11 03:32:48 UTC 2009</td>\n      <td>obama</td>\n      <td>kylesellers</td>\n      <td>@Karoli I firmly believe that Obama/Pelosi hav...</td>\n      <td>140</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4</td>\n      <td>Mon May 11 03:33:38 UTC 2009</td>\n      <td>obama</td>\n      <td>theviewfans</td>\n      <td>House Correspondents dinner was last night who...</td>\n      <td>106</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0</td>\n      <td>Sun May 17 17:32:00 UTC 2009</td>\n      <td>aig</td>\n      <td>KennyTRoland</td>\n      <td>?Obama Administration Must Stop Bonuses to AIG...</td>\n      <td>85</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>0</td>\n      <td>Mon May 25 17:35:23 UTC 2009</td>\n      <td>cheney</td>\n      <td>jepaco</td>\n      <td>Dick Cheney's dishonest speech about torture, ...</td>\n      <td>102</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>4</td>\n      <td>Mon May 11 03:29:01 UTC 2009</td>\n      <td>obama</td>\n      <td>lingbellbell</td>\n      <td>Obama is quite a good comedian! check out his ...</td>\n      <td>87</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>4</td>\n      <td>Mon May 11 03:29:38 UTC 2009</td>\n      <td>obama</td>\n      <td>motsandco</td>\n      <td>' Barack Obama shows his funny side \" &amp;gt;&amp;gt;...</td>\n      <td>82</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>4</td>\n      <td>Mon May 11 03:29:41 UTC 2009</td>\n      <td>obama</td>\n      <td>mickou</td>\n      <td>I like this guy : ' Barack Obama shows his fun...</td>\n      <td>85</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>4</td>\n      <td>Mon May 11 03:32:35 UTC 2009</td>\n      <td>obama</td>\n      <td>meggentile</td>\n      <td>Obama's speech was pretty awesome last night! ...</td>\n      <td>65</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>247</th>\n      <td>4</td>\n      <td>Mon May 11 03:33:05 UTC 2009</td>\n      <td>obama</td>\n      <td>failness</td>\n      <td>Reading  \"Bill Clinton Fail - Obama Win?\" http...</td>\n      <td>67</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>4</td>\n      <td>Mon May 11 03:33:43 UTC 2009</td>\n      <td>obama</td>\n      <td>kledy</td>\n      <td>Obama More Popular Than U.S. Among Arabs: Surv...</td>\n      <td>140</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>4</td>\n      <td>Mon May 11 03:34:04 UTC 2009</td>\n      <td>obama</td>\n      <td>LaurelEdelstein</td>\n      <td>Obama's got JOKES!! haha just got to watch a b...</td>\n      <td>128</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>0</td>\n      <td>Mon May 25 17:19:30 UTC 2009</td>\n      <td>north korea</td>\n      <td>Mvsic</td>\n      <td>Listening to Obama... Friggin North Korea...</td>\n      <td>44</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>0</td>\n      <td>Mon May 25 17:21:16 UTC 2009</td>\n      <td>pelosi</td>\n      <td>CFURNAROS</td>\n      <td>I just realized we three monkeys in the white ...</td>\n      <td>83</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>2</td>\n      <td>Tue Jun 02 03:00:51 UTC 2009</td>\n      <td>gm</td>\n      <td>economywire</td>\n      <td>Obama: Nationalization of GM to be short-term ...</td>\n      <td>78</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# count number of times Obama appears in tweets\n",
    "\n",
    "tweets_df['contains_obama'] = tweets_df.tweet.str.contains('Obama')\n",
    "\n",
    "# -> using Regex \n",
    "tweets_df['contains_obama'] = tweets_df.tweet.str.contains(r'\\bObama\\b')\n",
    "\n",
    "\n",
    "tweets_df[tweets_df['contains_obama'] == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter DataFrame for a Subset of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Between `extractall` and `findall`\n",
    "\n",
    "The `extractall` method will return a fanned-out multi-dimensional index. For example, in the example below, the primary index is `0`, but there are sub-indices for `stellargirl` (`0`), `loooooooovvvvvveee` (`1`), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          0\n",
       "  match                    \n",
       "0 0             stellargirl\n",
       "  1      loooooooovvvvvveee\n",
       "  2                 Kindle2\n",
       "  3                     Not\n",
       "  4                    that"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>match</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>stellargirl</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>loooooooovvvvvveee</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kindle2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Not</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>that</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "tweets_df[\"tweet\"].str.extractall(r'\\b(\\w{3,})\\b').head(5)\n",
    "# r'\\b(\\w{3,})\\b' every single word that is 3 or 3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "tweets_df[\"tweet\"].str.findall(\n",
    "  r'\\b(\\w{8,})\\b'  \n",
    ").apply(len).sum()\n",
    "\n",
    "# \\w includes: [a-zA-Z0-9]\n",
    "# \\s includes: \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `findall` method will return a list of results (or an empty list if there is no match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Character Classes\n",
    "\n",
    "There are often shortcut keywords you can use instead of typing out every possible character you want to match against. For instance, instead of `[a-zA-Z0-9]`, for all practical purposes, you can type out `/w`.\n",
    "\n",
    "![Character Classes](images/character_chars.png \"Regex character classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all Tweets That Start with a Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Non-Match Example](https://regexr.com/50ur7)\n",
    "* [Match Example](https://regexr.com/50urj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     likes                          date    topic       handle  \\\n",
       "242      2  Mon May 11 03:27:58 UTC 2009  twitter       delpop   \n",
       "430      2  Tue Jun 02 06:53:45 UTC 2009   eating  Fitness_101   \n",
       "482      0  Sun Jun 14 04:36:07 UTC 2009    latex    QuadError   \n",
       "\n",
       "                                                 tweet  tweet_length  \\\n",
       "242  45 Pros You Should Be Following on Twitter - h...            62   \n",
       "430  10 tips for healthy eating ? ResultsBy Fitness...            86   \n",
       "482  7 hours. 7 hours of inkscape crashing, normall...           140   \n",
       "\n",
       "     contains_obama  \n",
       "242           False  \n",
       "430           False  \n",
       "482           False  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>likes</th>\n      <th>date</th>\n      <th>topic</th>\n      <th>handle</th>\n      <th>tweet</th>\n      <th>tweet_length</th>\n      <th>contains_obama</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>242</th>\n      <td>2</td>\n      <td>Mon May 11 03:27:58 UTC 2009</td>\n      <td>twitter</td>\n      <td>delpop</td>\n      <td>45 Pros You Should Be Following on Twitter - h...</td>\n      <td>62</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>2</td>\n      <td>Tue Jun 02 06:53:45 UTC 2009</td>\n      <td>eating</td>\n      <td>Fitness_101</td>\n      <td>10 tips for healthy eating ? ResultsBy Fitness...</td>\n      <td>86</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>0</td>\n      <td>Sun Jun 14 04:36:07 UTC 2009</td>\n      <td>latex</td>\n      <td>QuadError</td>\n      <td>7 hours. 7 hours of inkscape crashing, normall...</td>\n      <td>140</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tweets_df[tweets_df['tweet'].str.contains(r'^\\d')] # all tweets start with numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df[tweets_df['tweet'].str.contains(r'\\d$')] # all tweets end with numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all @ Mentions\n",
    "We'll use the `\\w` character class to match for mentions (ie. `@ychennay`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      [@stellargirl]\n",
       "1                  []\n",
       "2                  []\n",
       "3       [@kenburbary]\n",
       "4         [@mikefish]\n",
       "            ...      \n",
       "493                []\n",
       "494                []\n",
       "495                []\n",
       "496                []\n",
       "497                []\n",
       "Name: tweet, Length: 498, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tweets_df['tweet'].str.findall(r'@\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# all tweets mention stella girl \n",
    "tweets_df['tweet'].str.findall(r'@\\w+').apply(lambda x: \"@stellargirl\" in x).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Method to Work With Lists in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifiers\n",
    "\n",
    "Quantifiers let you specify how many times a character or group should be matched.\n",
    "![Quantifiers](images/quantifiers.png \"Regex character classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Match All Phone Numbers ([Link](https://regexr.com/50v17))\n",
    "In the unwanted callers dataset (`unwanted_calls.csv`), parse out all phone numbers.\n",
    "\n",
    "We'll only consider for the time being phone numbers that follow the format `123-456-7890`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Parse Out Zip Codes ([Link](https://regexr.com/50v1g))\n",
    "In the `location_center_point_of_the_zip_code` field, we store both zip codes as well as geolocation data (latitudes and longitudes). We'll only consider zip codes with 5 digits (not the +4 digit delivery route)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Groups\n",
    "\n",
    "[Oracle documentation on Capture Groups:](https://docs.oracle.com/javase/tutorial/essential/regex/groups.html)\n",
    "> Capturing groups are a way to treat **multiple characters as a single unit**. They are created by placing the characters to be grouped inside a set of parentheses. For example, the regular expression `(dog)` creates a single group containing the letters `d`, `o`, and `g`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Parsing out Weekday from Timestamp String ([Link](https://regexr.com/50v0l))\n",
    "\n",
    "In the `date` field of `tweets_df`, we have timestamp strings that look like this: `Mon May 11 03:22:30 UTC 2009`. We want to parse out the weekday from this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Parsing Out Domain Names\n",
    "We want to capture the domain names of different websites. Here, we need to escape the `.` part of `www.google.com`. In regex, `.` means \"anything\". To actually indicate we want to match for the literal `.` period character, we need to escape it, using `\\.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = open(\"list_of_websites.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Capture Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you want to group multiple characters into a single unit to apply regex operations on them, but you don't\n",
    "want to actually capture or return their result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 [(Link)](https://regexr.com/50t7c)\n",
    "Using non-capture groups to match for optional text:\n",
    "\n",
    "You want to capture both `child` and `children` in your text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 [(Link)](https://regexr.com/50t7c)\n",
    "Find all the mentions in the tweets. Mentions start with `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 ([Link](https://regexr.com/50ush))\n",
    "Here we want to match for the dollar amount, but we don't want to include the currency notation (`$` or `USD`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Average fast food wage is $9.08, but inflation has increased USD9.23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "You'll be using the the `tweets_df` Pandas dataframe and `fraudulent_emails.txt` text files for these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_text = open(\"fraudulent_emails.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the subject headings for these emails.\n",
    "**Hint**: Look for the subject line within the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all hashtags mentioned in the `tweets_df` dataset. Store it as a separate column called **hashtags**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In `fraudulent_emails.txt`, identify the **list of email addresses** for your security administrator to blacklist from your company's email servers.\n",
    "\n",
    "* Not all emails are malicious! Provide only the list of email addresses from where the email originates from. **Hint**: identify the pattern in the emails that tells you the source of the email.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In `fraudulent_emails.txt`, identify any IP addresses that should be blacklisted\n",
    "\n",
    "An IPv4 address goes from **1.1.1.1 to 255.255.255.255**. For now, just worry about the number of digits, not whether the value in the address is above `255`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The word \"AT&T\" is not spelled correctly in the `tweets_df` dataset. Correct the misspelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing hashtags and mentions, which topic has the highest average tweet character count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "tweets_df = tweets_df[\"tweet\"].str.replace(r'AT&amp;', 'AT&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# first, we'll find the rows that contain AT&T to see what the pattern looks like\n",
    "tweets_df[tweets_df[\"tweet\"].str.contains(r'(AT)')].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}