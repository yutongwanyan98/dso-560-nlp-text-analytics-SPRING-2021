{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3\n",
    "\n",
    "Submit via Slack. Due on Tuesday, April 13th, 2020, 6:29pm PST. You may work with one other person.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "You are an analyst working at McDonalds as a store operations analyst, and charged with identifying areas for improvement for each franchise. Several metropolitan locations have been suffering recently from lower reviews.\n",
    "\n",
    "Using the **mcdonalds-yelp-negative-reviews.csv** dataset, clean and parse the text reviews. Explain the decisions you make:\n",
    "- why remove/keep stopwords?\n",
    "- which stopwords to remove?\n",
    "- stemming versus lemmatization?\n",
    "- regex cleaning and substitution?\n",
    "- adding in custom stopwords?\n",
    "- what `n` for your `n-grams`?\n",
    "- which words to collocate together?\n",
    "\n",
    "Finally, generate a TF-IDF report that either **visualizes** or explains for a business (non-technical) stakeholder:\n",
    "* the features your analysis showed that customers cited as reasons for a poor review\n",
    "* the most common issues identified from your analysis that generated customer dissatisfaction.\n",
    "\n",
    "Explain to what degree the TF-IDF findings make sense - what are its limitations?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/yutongwanyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/yutongwanyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/yutongwanyan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt') # A popular NLTK sentence tokenizer\n",
    "nltk.download('stopwords') # library of common English stopwords\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    _unit_id     city                                             review\n",
       "0  679455653  Atlanta  I'm not a huge mcds lover, but I've been to be...\n",
       "1  679455654  Atlanta  Terrible customer service. I came in at 9:30pm...\n",
       "2  679455655  Atlanta  First they \"lost\" my order, actually they gave...\n",
       "3  679455656  Atlanta  I see I'm not the only one giving 1 star. Only...\n",
       "4  679455657  Atlanta  Well, it's McDonald's, so you know what the fo..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_unit_id</th>\n      <th>city</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>679455653</td>\n      <td>Atlanta</td>\n      <td>I'm not a huge mcds lover, but I've been to be...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>679455654</td>\n      <td>Atlanta</td>\n      <td>Terrible customer service. I came in at 9:30pm...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>679455655</td>\n      <td>Atlanta</td>\n      <td>First they \"lost\" my order, actually they gave...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>679455656</td>\n      <td>Atlanta</td>\n      <td>I see I'm not the only one giving 1 star. Only...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>679455657</td>\n      <td>Atlanta</td>\n      <td>Well, it's McDonald's, so you know what the fo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# read the file \n",
    "yelp = pd.read_csv('mcdonalds-yelp-negative-reviews.csv', encoding='latin-1')\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the review \n",
    "reviews = yelp['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ma']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# stopwords.words('english')\n",
    "list_stopwords = stopwords.words('english')\n",
    "for i in list_stopwords:\n",
    "    if \"n't\" in i:\n",
    "        list_stopwords.remove(i)\n",
    "for i in ('don ain aren couldn didn doesn hadn hasn haven isn mightn mustn needn shan shouldn wasn weren won wouldn').split(' '):\n",
    "    if i in list_stopwords:\n",
    "        list_stopwords.remove(i)\n",
    "\n",
    "print(list_stopwords) \n",
    "\n",
    "# I removed stop words that related to xx-not as they express denial/negative feelings in the reviews. As we're trying to understand why McDonald is doing poorly in certain aspects, we should remove them out of stopword list to make sure we don't miss some negative reviews \n",
    "\n",
    "# The stopwords I keep are mostly pronouce and frequently used stopwords. They do not provide us significant information (unless we have a clear goal of study like if poor employee performance relates to gender etc; in that case we want to remove pronounces from this list as well)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       I 'm not a huge mcd lover , but I 've been to ...\n",
       "1       terribl custom servic . I came in at 9:30pm an...\n",
       "2       first they `` lost '' my order , actual they g...\n",
       "3       I see I 'm not the onli one give 1 star . onli...\n",
       "4       well , it 's mcdonald 's , so you know what th...\n",
       "                              ...                        \n",
       "1520    I enjoy the part where I repeatedli ask if I h...\n",
       "1521    worst mcdonald I 've been in in a long time ! ...\n",
       "1522    when I am realli crave for mcdonald 's , thi s...\n",
       "1523    two point right out of the gate : 1 . thuggeri...\n",
       "1524    I want to grab breakfast one morn befor work s...\n",
       "Name: review, Length: 1525, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "reviews = reviews.apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: [stemmer.stem(y) for y in x]).apply(lambda x: ' '.join(x))\n",
    "reviews\n",
    "\n",
    "# Similar in HW2, I decided to use stemming because it's \n",
    "# (1) working fast on a 1500+ rows series and \n",
    "# (2) I prefer to take more aggresive approach to reduce final dimensionalty of words or n-gram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More latex cleaning (improved from hw 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       I 'm not a huge mcd lover , but I 've been to ...\n",
       "1       terribl custom servic . I came in at 9:30pm an...\n",
       "2       first they `` lost '' my order , actual they g...\n",
       "3       I see I 'm not the onli one give 1 star . onli...\n",
       "4       well , it 's mcd 's , so you know what the foo...\n",
       "                              ...                        \n",
       "1520    I enjoy the part where I repeatedli ask if I h...\n",
       "1521    worst mcd I 've been in in a long time ! dirt ...\n",
       "1522    when I am realli crave for mcd 's , thi seem t...\n",
       "1523    two point right out of the gate : 1 . thuggeri...\n",
       "1524    I want to grab breakfast one morn befor work s...\n",
       "Name: review, Length: 1525, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# more latex cleaning (improved from hw 2)\n",
    "\n",
    "pattern_dict = {\n",
    "    r'(\\w+burger\\b)':'burger',\n",
    "    r'(\\bbarbe+\\w+|bbq)':'barbeque',\n",
    "    r'(\\bchoco+\\w+\\b)':'chocolate',\n",
    "    r'(\\bcoffe+\\w+)':\"coffee\",\n",
    "    r'(\\bfrap+\\w+)':'frappuccino',\n",
    "    r'(\\bdirt+\\w+)':'dirty',\n",
    "    r'(\\bdisa+\\w+t)':'disappoint',\n",
    "    r'(\\bhm|hmm+\\w)':'hmm',\n",
    "    r'(\\blettuce+\\w)':'lettuce',\n",
    "    r'(\\blo+\\w+g)':'long',\n",
    "    r'(\\blow|low+\\w)':'low',\n",
    "    r'(\\bmcdo+\\w+|mcd+\\w\\b)':'mcd',\n",
    "    r'(\\bmcchichen|mcchicken)':'mcchicken',\n",
    "    r'(\\bm+\\w+m|mm)':'m'\n",
    "} # again, these are some examples for regex cleaning; most of them I choose here are food names and stop words we can add later into the stopword list\n",
    "\n",
    "for i in pattern_dict:\n",
    "    reviews = reviews.apply(lambda x: re.sub(i, pattern_dict[i], x))\n",
    "reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of add stop words we created from regex cleaninig\n",
    "\n",
    "list_stopwords = list_stopwords + [\n",
    "    'hmm',\n",
    "    'get',\n",
    "    'thi',\n",
    "    'look',\n",
    "    'ever'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorize the Documents\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(reviews) \n",
    "X = X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataframe shape was (1525, 6383)\nDataframe shape is now (1525, 6269)\n"
     ]
    }
   ],
   "source": [
    "corpus_df = pd.DataFrame(X, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# iterate through the Pandas dataframe, and drop the columns that reflect stopwords:\n",
    "original_columns = corpus_df.columns # get existing columns\n",
    "\n",
    "to_drop_columns = set(original_columns).intersection(set(list_stopwords)) # get the list of words to drop\n",
    "\n",
    "# before drop stopwords\n",
    "print(f\"Dataframe shape was {corpus_df.shape}\")\n",
    "\n",
    "# after drop stopwords \n",
    "corpus_df.drop(columns=to_drop_columns, inplace=True)\n",
    "print(f\"Dataframe shape is now {corpus_df.shape}\")\n",
    "\n",
    "# NOW if compared to the same step of hw2, the number of columns (after removing stop words) are reduced from 6327 to 6269\n",
    "# it shows that both regex cleaning and stopwords manipulation have worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      00  000  00am  00mi  00pm  01  0200  03pm  04  04am  ...  zax  zee  \\\n",
       "0      0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "1      0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "2      0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "3      0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "4      0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "...   ..  ...   ...   ...   ...  ..   ...   ...  ..   ...  ...  ...  ...   \n",
       "1520   0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "1521   0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "1522   0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "1523   0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "1524   0    0     0     0     0   0     0     0   0     0  ...    0    0   \n",
       "\n",
       "      zeke  zero  zesti  zip  zombi  zombie  zoom  î_  \n",
       "0        0     0      0    0      0       0     0   0  \n",
       "1        0     0      0    0      0       0     0   0  \n",
       "2        0     0      0    0      0       0     0   0  \n",
       "3        0     0      0    0      0       0     0   0  \n",
       "4        0     0      0    0      0       0     0   0  \n",
       "...    ...   ...    ...  ...    ...     ...   ...  ..  \n",
       "1520     0     0      0    0      0       0     0   0  \n",
       "1521     0     0      0    0      0       0     0   0  \n",
       "1522     0     0      0    0      0       0     0   0  \n",
       "1523     0     1      0    0      0       0     0   0  \n",
       "1524     0     0      0    0      0       0     0   0  \n",
       "\n",
       "[1525 rows x 6269 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>00am</th>\n      <th>00mi</th>\n      <th>00pm</th>\n      <th>01</th>\n      <th>0200</th>\n      <th>03pm</th>\n      <th>04</th>\n      <th>04am</th>\n      <th>...</th>\n      <th>zax</th>\n      <th>zee</th>\n      <th>zeke</th>\n      <th>zero</th>\n      <th>zesti</th>\n      <th>zip</th>\n      <th>zombi</th>\n      <th>zombie</th>\n      <th>zoom</th>\n      <th>î_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1520</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1521</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1522</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1523</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1524</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1525 rows × 6269 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report tf_idf, using bi-gram\n",
    "\n",
    "# first define re-usable function\n",
    "\n",
    "def get_tf_idf(documents, ngram_range=(1,1), stop_word_true = True, stopword_list = list_stopwords):\n",
    "    '''\n",
    "    documents: a list of documents, as the corpus\n",
    "    ngram_range: a tuple for n-gram size\n",
    "    stop_word_true: if remove stopwords \n",
    "    stopword_list: a list of stopwords defined by user; by default list_stopwords\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    corpus = documents\n",
    "\n",
    "    if stop_word_true == True:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range,\n",
    "                                    token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                    # max_df=0.4, \n",
    "                                    stop_words=stopword_list\n",
    "                                    )\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range,\n",
    "                                token_pattern=r'\\b[a-zA-Z]{3,}\\b'\n",
    "                                )\n",
    "\n",
    "                                \n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "    tf_idf = tf_idf.sum(axis=1)\n",
    "    score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "    score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of word combination/collocations: 49843\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    score\n",
       "drive thru      24.967784\n",
       "fast food       10.857615\n",
       "worst mcd       10.079700\n",
       "custom servic    9.635739\n",
       "ice cream        6.737402\n",
       "order wrong      6.484587\n",
       "big mac          5.701065\n",
       "take order       5.543923\n",
       "wait minut       5.466364\n",
       "everi time       5.107380\n",
       "order right      4.992328\n",
       "place order      4.397336\n",
       "mess order       4.385047\n",
       "chicken nugget   4.358886\n",
       "late night       4.257971\n",
       "ice coffe        3.981700\n",
       "park lot         3.851295\n",
       "french fri       3.671405\n",
       "tast like        3.658143\n",
       "egg muffin       3.564226"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drive thru</th>\n      <td>24.967784</td>\n    </tr>\n    <tr>\n      <th>fast food</th>\n      <td>10.857615</td>\n    </tr>\n    <tr>\n      <th>worst mcd</th>\n      <td>10.079700</td>\n    </tr>\n    <tr>\n      <th>custom servic</th>\n      <td>9.635739</td>\n    </tr>\n    <tr>\n      <th>ice cream</th>\n      <td>6.737402</td>\n    </tr>\n    <tr>\n      <th>order wrong</th>\n      <td>6.484587</td>\n    </tr>\n    <tr>\n      <th>big mac</th>\n      <td>5.701065</td>\n    </tr>\n    <tr>\n      <th>take order</th>\n      <td>5.543923</td>\n    </tr>\n    <tr>\n      <th>wait minut</th>\n      <td>5.466364</td>\n    </tr>\n    <tr>\n      <th>everi time</th>\n      <td>5.107380</td>\n    </tr>\n    <tr>\n      <th>order right</th>\n      <td>4.992328</td>\n    </tr>\n    <tr>\n      <th>place order</th>\n      <td>4.397336</td>\n    </tr>\n    <tr>\n      <th>mess order</th>\n      <td>4.385047</td>\n    </tr>\n    <tr>\n      <th>chicken nugget</th>\n      <td>4.358886</td>\n    </tr>\n    <tr>\n      <th>late night</th>\n      <td>4.257971</td>\n    </tr>\n    <tr>\n      <th>ice coffe</th>\n      <td>3.981700</td>\n    </tr>\n    <tr>\n      <th>park lot</th>\n      <td>3.851295</td>\n    </tr>\n    <tr>\n      <th>french fri</th>\n      <td>3.671405</td>\n    </tr>\n    <tr>\n      <th>tast like</th>\n      <td>3.658143</td>\n    </tr>\n    <tr>\n      <th>egg muffin</th>\n      <td>3.564226</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# create corpus \n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in reviews:\n",
    "    corpus.append(i)\n",
    "\n",
    "# report tf_idf\n",
    "tf_idf_score = get_tf_idf(corpus, ngram_range=(2,2), stop_word_true = True)\n",
    "print(f'Number of word combination/collocations: {tf_idf_score.shape[0]}')\n",
    "tf_idf_score[:20]\n",
    "\n",
    "# if we choose 2 for n-gram, we get some words collocated together that are frequently used. Show top 20 as examples.\n",
    "# some word combinations make sense, like drive thru, fast food, big mac, ice cream etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of word combination/collocations: 64816\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      score\n",
       "drive thru window  2.447772\n",
       "went drive thru    2.441666\n",
       "drive thru order   2.390912\n",
       "got order wrong    2.323411\n",
       "drive thru line    2.322075\n",
       "fast food place    1.908174\n",
       "everi singl time   1.778436\n",
       "never order right  1.599128\n",
       "ice cream cone     1.553606\n",
       "ice cream machin   1.533518"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drive thru window</th>\n      <td>2.447772</td>\n    </tr>\n    <tr>\n      <th>went drive thru</th>\n      <td>2.441666</td>\n    </tr>\n    <tr>\n      <th>drive thru order</th>\n      <td>2.390912</td>\n    </tr>\n    <tr>\n      <th>got order wrong</th>\n      <td>2.323411</td>\n    </tr>\n    <tr>\n      <th>drive thru line</th>\n      <td>2.322075</td>\n    </tr>\n    <tr>\n      <th>fast food place</th>\n      <td>1.908174</td>\n    </tr>\n    <tr>\n      <th>everi singl time</th>\n      <td>1.778436</td>\n    </tr>\n    <tr>\n      <th>never order right</th>\n      <td>1.599128</td>\n    </tr>\n    <tr>\n      <th>ice cream cone</th>\n      <td>1.553606</td>\n    </tr>\n    <tr>\n      <th>ice cream machin</th>\n      <td>1.533518</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# if we choose n = 3\n",
    "\n",
    "tf_idf_score = get_tf_idf(corpus, ngram_range=(3,3), stop_word_true = True)\n",
    "print(f'Number of word combination/collocations: {tf_idf_score.shape[0]}')\n",
    "tf_idf_score[:10]\n",
    "\n",
    "# from the top results, we can see first 3 combinations are all about drive through; this indicates that n = 2 is more efficient than n = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Attribution (Feature Engineering and Regex Practice)\n",
    "\n",
    "Download the [dataset](https://dso-560-nlp-text-analytics.s3.amazonaws.com/truncated_catalog.csv) from the class S3 bucket (`dso560-nlp-text-analytics`).\n",
    "\n",
    "In preparation for the group project, our client company has provided a dataset of women's clothing products they are considering cataloging. \n",
    "\n",
    "1. Filter for only **women's clothing items**.\n",
    "\n",
    "2. For each clothing item:\n",
    "\n",
    "* Identify its **category**:\n",
    "```\n",
    "Bottom\n",
    "One Piece\n",
    "Shoe\n",
    "Handbag\n",
    "Scarf\n",
    "```\n",
    "* Identify its **color**:\n",
    "```\n",
    "Beige\n",
    "Black\n",
    "Blue\n",
    "Brown\n",
    "Burgundy\n",
    "Gold\n",
    "Gray\n",
    "Green\n",
    "Multi \n",
    "Navy\n",
    "Neutral\n",
    "Orange\n",
    "Pinks\n",
    "Purple\n",
    "Red\n",
    "Silver\n",
    "Teal\n",
    "White\n",
    "Yellow\n",
    "```\n",
    "\n",
    "Your output will be the same dataset, except with **3 additional fields**:\n",
    "* `is_womens_clothing`\n",
    "* `product_category`\n",
    "* `colors`\n",
    "\n",
    "`colors` should be a list of colors, since it is possible for a piece of clothing to have multiple colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              ï»¿brand                                               name  \\\n",
       "0                 FILA                          Original Fitness Sneakers   \n",
       "1               CHANEL                                                HAT   \n",
       "2                Frame                             Petit Oval Buckle Belt   \n",
       "3  Lilly Pulitzer Kids  Little Gir's & Girl's Ariana One-Piece UPF 50+...   \n",
       "4          Kissy Kissy  Baby Girl's Endearing Elephants Pima Cotton Co...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Vintage Fitness leather sneakers with logo pri...   \n",
       "1                                                NaN   \n",
       "2  A Timeless Leather Belt Crafted From Smooth Co...   \n",
       "3  Pretty ruffle sleeves and trim elevate essenti...   \n",
       "4  Versatile convertible gown with elephant applique   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                 TheMensStore/Shoes/Sneakers/LowTop   \n",
       "1                                            Unknown   \n",
       "2                                        Accessories   \n",
       "3  JustKids/Girls214/Girls/SwimwearCoverups,JustK...   \n",
       "4  JustKids/Baby024months/InfantGirls/FootiesRompers   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://www.saksfifthavenue.com/fila-original-...   \n",
       "1  https://www.saksfifthavenue.com/chanel-hat/pro...   \n",
       "2  https://frame-store.com/products/petit-oval-bu...   \n",
       "3  https://www.saksfifthavenue.com/lilly-pulitzer...   \n",
       "4  https://www.saksfifthavenue.com/kissy-kissy-ba...   \n",
       "\n",
       "                                             details  \\\n",
       "0  Leather/synthetic upper\\nLace-up closure\\nText...   \n",
       "1                                  WOOL TWEED & FELT   \n",
       "2                                                NaN   \n",
       "3  Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...   \n",
       "4  V-neckline\\nLong sleeves\\nFront snap closure\\n...   \n",
       "\n",
       "                                                 tsv  \n",
       "0  'design':12 'fila':1A 'fit':3A,6 'leather':7 '...  \n",
       "1                               'chanel':1A 'hat':2A  \n",
       "2  'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...  \n",
       "3  '50':14A 'allov':28 'ariana':9A 'color':27 'el...  \n",
       "4  'appliqu':17 'babi':3A 'convert':10A,13 'cotto...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ï»¿brand</th>\n      <th>name</th>\n      <th>description</th>\n      <th>brand_category</th>\n      <th>brand_canonical_url</th>\n      <th>details</th>\n      <th>tsv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FILA</td>\n      <td>Original Fitness Sneakers</td>\n      <td>Vintage Fitness leather sneakers with logo pri...</td>\n      <td>TheMensStore/Shoes/Sneakers/LowTop</td>\n      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n      <td>Leather/synthetic upper\\nLace-up closure\\nText...</td>\n      <td>'design':12 'fila':1A 'fit':3A,6 'leather':7 '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHANEL</td>\n      <td>HAT</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n      <td>WOOL TWEED &amp; FELT</td>\n      <td>'chanel':1A 'hat':2A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Frame</td>\n      <td>Petit Oval Buckle Belt</td>\n      <td>A Timeless Leather Belt Crafted From Smooth Co...</td>\n      <td>Accessories</td>\n      <td>https://frame-store.com/products/petit-oval-bu...</td>\n      <td>NaN</td>\n      <td>'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lilly Pulitzer Kids</td>\n      <td>Little Gir's &amp; Girl's Ariana One-Piece UPF 50+...</td>\n      <td>Pretty ruffle sleeves and trim elevate essenti...</td>\n      <td>JustKids/Girls214/Girls/SwimwearCoverups,JustK...</td>\n      <td>https://www.saksfifthavenue.com/lilly-pulitzer...</td>\n      <td>Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...</td>\n      <td>'50':14A 'allov':28 'ariana':9A 'color':27 'el...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kissy Kissy</td>\n      <td>Baby Girl's Endearing Elephants Pima Cotton Co...</td>\n      <td>Versatile convertible gown with elephant applique</td>\n      <td>JustKids/Baby024months/InfantGirls/FootiesRompers</td>\n      <td>https://www.saksfifthavenue.com/kissy-kissy-ba...</td>\n      <td>V-neckline\\nLong sleeves\\nFront snap closure\\n...</td>\n      <td>'appliqu':17 'babi':3A 'convert':10A,13 'cotto...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "catalog = pd.read_csv('truncated_catalog.csv', encoding='latin-1')\n",
    "catalog.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## women clothes ? \n",
    "- 1 = True, 0 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['if_womens_clothing'] = [0 for i in range(len(catalog))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.92 s, sys: 10.3 ms, total: 1.93 s\nWall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for col in ['name', 'brand_category', 'brand_canonical_url']:\n",
    "    for i in range(len(catalog[col])):\n",
    "\n",
    "        if re.search(\n",
    "                r'(\\bgir\\w+|wom[ea]\\w+|dre[a-zA-Z]+s\\b|skir+\\w+)', # search for girl, women, dress, skirt \n",
    "                str(catalog[col][i]).lower()\n",
    "            ) and catalog.if_womens_clothing[i] == 0:\n",
    "\n",
    "            catalog['if_womens_clothing'][i] += 1\n",
    "\n",
    "# there are many other items that are not labelled with specific gender; we ignore them for just now to keep the question simple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_category = {\n",
    "    r'(\\bpants|skir|\\w+pants|bottom|jeans|trouser|legg|shorts+\\w\\b)': 'bottom',\n",
    "    r'(\\b\\w+suit|dress|one+ +piece\\b)': 'One Piece',\n",
    "    r'(\\bsneaker|pumps|shoe|hill|slipper|loafer|slide|boot|\\w+boot)': 'Shoe',\n",
    "    r'(\\b(\\w+bag)|bag|handbag|backpack|wallet|purse)': 'Handbag',\n",
    "    r'(\\bscarf|tie)': 'Scarf'\n",
    "}\n",
    "\n",
    "# these pattern construction only measure the best chances for each item to be categorized correctly; if one item belongs to 2 or more categories or has certain word in the name, there might be some mistakes \n",
    "\n",
    "# Bottom\n",
    "    # xxxpants\n",
    "    # jeans\n",
    "    # skirt\n",
    "    # bottom\n",
    "    # trouser\n",
    "    # leggin\n",
    "    # shorts\n",
    "    # chino\n",
    "\n",
    "# One Piece\n",
    "    # swimsuit\n",
    "    # dress\n",
    "    # jumpsuit\n",
    "\n",
    "# Shoe\n",
    "    # sneakers \n",
    "    # pumps \n",
    "    # shoes\n",
    "    # hills\n",
    "    # loafer\n",
    "    # slipper\n",
    "    # slides\n",
    "    # boots\n",
    "\n",
    "# Handbag\n",
    "    # backpack\n",
    "    # bag\n",
    "    # handbad\n",
    "    # wallet\n",
    "    # purse\n",
    "    # wallet\n",
    "\n",
    "# Scarf\n",
    "    #scarf\n",
    "    #tie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        original fitness sneakers themensstore shoes s...\n",
       "1                                              hat unknown\n",
       "2                       petit oval buckle belt accessories\n",
       "3        little gir's & girl's ariana one-piece upf 50+...\n",
       "4        baby girl's endearing elephants pima cotton co...\n",
       "                               ...                        \n",
       "42368    atlas oversized belted mã©lange wool coat clot...\n",
       "42369    cropped crochet-trimmed georgette top clothing...\n",
       "42370    juna cotton-corduroy mini skirt clothing skirt...\n",
       "42371    annabel rigid mid-rise skinny jean women cloth...\n",
       "42372    kessler colorblock track jacket themensstore a...\n",
       "Name: name_cate, Length: 42373, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# catalog = pd.read_csv('truncated_catalog.csv', encoding='latin-1')\n",
    "# catalog.head()\n",
    "\n",
    "for i in [' / ','/', '>', ':', ',']:\n",
    "    catalog['brand_category'] = catalog['brand_category'].apply(lambda x: x.replace(i,' ').lower())\n",
    "catalog['brand_category']\n",
    "\n",
    "# concat name and brand category to capture category information as much as possible \n",
    "# I decided not to include column description because the descriptions contain many extra information to proceed\n",
    "\n",
    "catalog['name_cate'] = catalog['name'].str.lower() +' '+ catalog['brand_category']\n",
    "catalog['name_cate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "catalog['category'] = pd.Series()\n",
    "\n",
    "for i in range(len(catalog['name_cate'])):\n",
    "    for ii in dict_category:\n",
    "        if re.search(\n",
    "                ii,\n",
    "                catalog['name_cate'][i]\n",
    "            ):\n",
    "\n",
    "            catalog['category'][i] = dict_category[ii]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0             Shoe\n",
       "1              NaN\n",
       "2              NaN\n",
       "3        One Piece\n",
       "4            Scarf\n",
       "           ...    \n",
       "42368          NaN\n",
       "42369          NaN\n",
       "42370       bottom\n",
       "42371       bottom\n",
       "42372          NaN\n",
       "Name: category, Length: 42373, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "catalog['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        original fitness sneakers themensstore shoes s...\n",
       "1                                          hat unknown nan\n",
       "2        petit oval buckle belt accessories a timeless ...\n",
       "3        little gir's & girl's ariana one-piece upf 50+...\n",
       "4        baby girl's endearing elephants pima cotton co...\n",
       "                               ...                        \n",
       "42368    atlas oversized belted mã©lange wool coat clot...\n",
       "42369    cropped crochet-trimmed georgette top clothing...\n",
       "42370    juna cotton-corduroy mini skirt clothing skirt...\n",
       "42371    annabel rigid mid-rise skinny jean women cloth...\n",
       "42372    kessler colorblock track jacket themensstore a...\n",
       "Name: name_cate_des, Length: 42373, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# most color infor in the column descriptions, so we concat description to column name_cate\n",
    "for i in [',', '.']:\n",
    "    catalog['description'] = catalog['description'].apply(lambda x: str(x).replace(i,'').lower())\n",
    "\n",
    "catalog['name_cate_des'] = catalog['name_cate']+' '+catalog['description']\n",
    "catalog['name_cate_des']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "catalog['color'] = pd.Series()\n",
    "\n",
    "for i in range(len(catalog['name_cate_des'])):\n",
    "    result =  re.findall(\n",
    "        r'(\\bbeige|black|blue|brown|burgundy|gold|grey|gray|green|navy|neutral|organge|pinks|purple|red|silver|teal|white|yellow\\b)',\n",
    "        catalog['name_cate_des'][i]\n",
    "    )\n",
    "\n",
    "    if len(result) > 1:\n",
    "        catalog['color'][i] = 'multi'\n",
    "    elif len(result) == 0:\n",
    "        catalog['color'][i] = np.nan\n",
    "    else:\n",
    "        catalog['color'][i] = result[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1          NaN\n",
       "2         gold\n",
       "3          NaN\n",
       "4          NaN\n",
       "         ...  \n",
       "42368    beige\n",
       "42369      NaN\n",
       "42370      NaN\n",
       "42371      NaN\n",
       "42372      NaN\n",
       "Name: color, Length: 42373, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "catalog['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               ï»¿brand                                               name  \\\n",
       "0                  FILA                          Original Fitness Sneakers   \n",
       "1                CHANEL                                                HAT   \n",
       "2                 Frame                             Petit Oval Buckle Belt   \n",
       "3   Lilly Pulitzer Kids  Little Gir's & Girl's Ariana One-Piece UPF 50+...   \n",
       "4           Kissy Kissy  Baby Girl's Endearing Elephants Pima Cotton Co...   \n",
       "5               Jocelyn  Savage Love Texty Time Leopard-Print Rabbit Fu...   \n",
       "6                Theory                         Teah stretch-silk camisole   \n",
       "7             AMI Paris                              Postcard Patch Hoodie   \n",
       "8        Alexander Wang                          Layered velvet mini dress   \n",
       "9                J.Crew                                  Wide leather belt   \n",
       "10               J.Crew                    Faux-leather pleated midi skirt   \n",
       "11       Alexander Wang  Parker logo-embellished snake-effect leather a...   \n",
       "12                Frame                                    Le Garcon--NOIR   \n",
       "13                  TDE                              Leather iPhone X Case   \n",
       "14               Hatley                 Little Kid's & Kid's Splash Jacket   \n",
       "15             Tom Ford            Miranda 68MM Oversized Round Sunglasses   \n",
       "16            Montblanc                        Horseshoe Buckle Suede Belt   \n",
       "17               Theory                              Silk-crepe midi dress   \n",
       "18               J.Crew  Tall stretch Secret Wash shirt in square conne...   \n",
       "19               J.Crew  Loeffler RandallÂ® Emilia pleated knot slide s...   \n",
       "\n",
       "                                          description  \\\n",
       "0   vintage fitness leather sneakers with logo pri...   \n",
       "1                                                 nan   \n",
       "2   a timeless leather belt crafted from smooth co...   \n",
       "3   pretty ruffle sleeves and trim elevate essenti...   \n",
       "4   versatile convertible gown with elephant applique   \n",
       "5   from the savage love collection fingerless kni...   \n",
       "6   beige stretch-silk slips on 93% silk 7% spande...   \n",
       "7   casual cotton-blend hoodie with an embossed la...   \n",
       "8   black velvet concealed hook and zip fastening ...   \n",
       "9   the ideal way to add definition to your favori...   \n",
       "10  with accordion pleats and a flattering midi le...   \n",
       "11  heel measures approximately 75mm/ 3 inches sna...   \n",
       "12  a sophisticated boyfriend jean with a tailored...   \n",
       "13  essential phone case cut from rich saffiano le...   \n",
       "14  colorful raincoat with cozy lining keeps them ...   \n",
       "15  oversized crossover metal frame with open temp...   \n",
       "16  horse-shoe shaped palladium-coated pin buckle ...   \n",
       "17  black silk-crepe concealed zip fastening along...   \n",
       "18  meet the pinnacle of shirt engineering a custo...   \n",
       "19  step up your sandal game with this best seller...   \n",
       "\n",
       "                                       brand_category  \\\n",
       "0                  themensstore shoes sneakers lowtop   \n",
       "1                                             unknown   \n",
       "2                                         accessories   \n",
       "3   justkids girls214 girls swimwearcoverups justk...   \n",
       "4   justkids baby024months infantgirls footiesrompers   \n",
       "5               jewelryaccessories accessories gloves   \n",
       "6                       clothing tops tanks and camis   \n",
       "7         themensstore apparel sweatshirtshoodies18q1   \n",
       "8                               clothing dresses mini   \n",
       "9                                               belts   \n",
       "10                                             skirts   \n",
       "11                                  shoes boots ankle   \n",
       "12                                              jeans   \n",
       "13  jewelryaccessories accessories mobiletechcases...   \n",
       "14  justkids boys220 toddlerboys24 outerwear justk...   \n",
       "15  jewelryaccessories sunglassesreaders oversized...   \n",
       "16                     themensstore accessories belts   \n",
       "17                              clothing dresses midi   \n",
       "18                                             shirts   \n",
       "19                                              shoes   \n",
       "\n",
       "                                  brand_canonical_url  \\\n",
       "0   https://www.saksfifthavenue.com/fila-original-...   \n",
       "1   https://www.saksfifthavenue.com/chanel-hat/pro...   \n",
       "2   https://frame-store.com/products/petit-oval-bu...   \n",
       "3   https://www.saksfifthavenue.com/lilly-pulitzer...   \n",
       "4   https://www.saksfifthavenue.com/kissy-kissy-ba...   \n",
       "5   https://www.saksfifthavenue.com/jocelyn-savage...   \n",
       "6   https://www.net-a-porter.com/us/en/product/119...   \n",
       "7   https://www.saksfifthavenue.com/ami-paris-post...   \n",
       "8   https://www.net-a-porter.com/us/en/product/120...   \n",
       "9   https://www.jcrew.com/p/womens_category/belts/...   \n",
       "10  https://www.jcrew.com/p/womens_category/skirts...   \n",
       "11  https://www.net-a-porter.com/us/en/product/115...   \n",
       "12    https://frame-store.com/products/le-garcon-noir   \n",
       "13  https://www.saksfifthavenue.com/tde-leather-ip...   \n",
       "14  https://www.saksfifthavenue.com/hatley-little-...   \n",
       "15  https://www.saksfifthavenue.com/tom-ford-miran...   \n",
       "16  https://www.saksfifthavenue.com/montblanc-hors...   \n",
       "17  https://www.net-a-porter.com/us/en/product/120...   \n",
       "18  https://www.jcrew.com/p/mens_category/shirts/t...   \n",
       "19  https://www.jcrew.com/p/womens_category/shoes/...   \n",
       "\n",
       "                                              details  \\\n",
       "0   Leather/synthetic upper\\nLace-up closure\\nText...   \n",
       "1                                   WOOL TWEED & FELT   \n",
       "2                                                 NaN   \n",
       "3   Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...   \n",
       "4   V-neckline\\nLong sleeves\\nFront snap closure\\n...   \n",
       "5   Acrylic/wool\\nFur type: Dyed rabbit\\nFur origi...   \n",
       "6   Fits true to size, take your normal size\\nCut ...   \n",
       "7   Attached drawstring hood\\nLong sleeves\\nPullov...   \n",
       "8   Fits true to size, take your normal size \\nDes...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11  Fits true to size, take your normal size \\nIta...   \n",
       "12                                                NaN   \n",
       "13  Dust bag included\\nRubber lining\\nSaffiano lea...   \n",
       "14  Attached hood\\nLong sleeves\\nSnap button front...   \n",
       "15  100% UV protection\\nGradient brown lenses\\nAdj...   \n",
       "16  Self-adjustable\\nSilvertone hardware\\nLeather\\...   \n",
       "17  Fits true to size, take your normal size\\nCut ...   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "                                                  tsv  if_womens_clothing  \\\n",
       "0   'design':12 'fila':1A 'fit':3A,6 'leather':7 '...                   0   \n",
       "1                                'chanel':1A 'hat':2A                   0   \n",
       "2   'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...                   0   \n",
       "3   '50':14A 'allov':28 'ariana':9A 'color':27 'el...                   1   \n",
       "4   'appliqu':17 'babi':3A 'convert':10A,13 'cotto...                   1   \n",
       "5   'ad':29 'collect':16 'craft':20 'fingerless':1...                   0   \n",
       "6   '7':15 '93':13 'beig':7 'camisol':6A 'clean':1...                   0   \n",
       "7   'ami':1A,15 'blend':9 'casual':6 'chest':21 'c...                   0   \n",
       "8   '100':21 '35':18 '65':16 'alexand':1A 'back':1...                   1   \n",
       "9   'add':9 'belt':4A,17 'better':27 'custom':19 '...                   1   \n",
       "10  'accordion':9 'faux':3A,18 'faux-leath':2A,17 ...                   1   \n",
       "11  '3':17 '75mm':16 'alexand':1A 'along':26 'ankl...                   0   \n",
       "12  'black':18 'boyfriend':7 'craft':15 'denim':19...                   0   \n",
       "13  'case':5A,8 'cut':9 'essenti':6 'iphon':3A 'le...                   0   \n",
       "14  'color':9 'cozi':12 'hatley':1A 'jacket':8A 'k...                   1   \n",
       "15  '68mm':4A 'avail':18 'brown':24 'crossov':9 'f...                   0   \n",
       "16  'antiqu':16 'belt':5A 'buckl':3A,14 'coat':12 ...                   0   \n",
       "17  '100':16,24 '35':21 '65':19 'along':14 'back':...                   1   \n",
       "18  '2005':22 'achiev':87 'ad':64 'better':48 'bro...                   0   \n",
       "19  'accessori':25 'action':43 'aka':37 'base':21 ...                   1   \n",
       "\n",
       "     category  color  \n",
       "0        Shoe    NaN  \n",
       "1         NaN    NaN  \n",
       "2         NaN   gold  \n",
       "3   One Piece    NaN  \n",
       "4       Scarf    NaN  \n",
       "5         NaN    NaN  \n",
       "6         NaN  beige  \n",
       "7         NaN    NaN  \n",
       "8   One Piece  multi  \n",
       "9         NaN    NaN  \n",
       "10     bottom    NaN  \n",
       "11       Shoe    NaN  \n",
       "12     bottom  multi  \n",
       "13    Handbag    NaN  \n",
       "14        NaN    NaN  \n",
       "15        NaN  multi  \n",
       "16       Shoe    NaN  \n",
       "17  One Piece  black  \n",
       "18        NaN    NaN  \n",
       "19       Shoe   gold  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ï»¿brand</th>\n      <th>name</th>\n      <th>description</th>\n      <th>brand_category</th>\n      <th>brand_canonical_url</th>\n      <th>details</th>\n      <th>tsv</th>\n      <th>if_womens_clothing</th>\n      <th>category</th>\n      <th>color</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FILA</td>\n      <td>Original Fitness Sneakers</td>\n      <td>vintage fitness leather sneakers with logo pri...</td>\n      <td>themensstore shoes sneakers lowtop</td>\n      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n      <td>Leather/synthetic upper\\nLace-up closure\\nText...</td>\n      <td>'design':12 'fila':1A 'fit':3A,6 'leather':7 '...</td>\n      <td>0</td>\n      <td>Shoe</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHANEL</td>\n      <td>HAT</td>\n      <td>nan</td>\n      <td>unknown</td>\n      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n      <td>WOOL TWEED &amp; FELT</td>\n      <td>'chanel':1A 'hat':2A</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Frame</td>\n      <td>Petit Oval Buckle Belt</td>\n      <td>a timeless leather belt crafted from smooth co...</td>\n      <td>accessories</td>\n      <td>https://frame-store.com/products/petit-oval-bu...</td>\n      <td>NaN</td>\n      <td>'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>gold</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lilly Pulitzer Kids</td>\n      <td>Little Gir's &amp; Girl's Ariana One-Piece UPF 50+...</td>\n      <td>pretty ruffle sleeves and trim elevate essenti...</td>\n      <td>justkids girls214 girls swimwearcoverups justk...</td>\n      <td>https://www.saksfifthavenue.com/lilly-pulitzer...</td>\n      <td>Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...</td>\n      <td>'50':14A 'allov':28 'ariana':9A 'color':27 'el...</td>\n      <td>1</td>\n      <td>One Piece</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kissy Kissy</td>\n      <td>Baby Girl's Endearing Elephants Pima Cotton Co...</td>\n      <td>versatile convertible gown with elephant applique</td>\n      <td>justkids baby024months infantgirls footiesrompers</td>\n      <td>https://www.saksfifthavenue.com/kissy-kissy-ba...</td>\n      <td>V-neckline\\nLong sleeves\\nFront snap closure\\n...</td>\n      <td>'appliqu':17 'babi':3A 'convert':10A,13 'cotto...</td>\n      <td>1</td>\n      <td>Scarf</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jocelyn</td>\n      <td>Savage Love Texty Time Leopard-Print Rabbit Fu...</td>\n      <td>from the savage love collection fingerless kni...</td>\n      <td>jewelryaccessories accessories gloves</td>\n      <td>https://www.saksfifthavenue.com/jocelyn-savage...</td>\n      <td>Acrylic/wool\\nFur type: Dyed rabbit\\nFur origi...</td>\n      <td>'ad':29 'collect':16 'craft':20 'fingerless':1...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Theory</td>\n      <td>Teah stretch-silk camisole</td>\n      <td>beige stretch-silk slips on 93% silk 7% spande...</td>\n      <td>clothing tops tanks and camis</td>\n      <td>https://www.net-a-porter.com/us/en/product/119...</td>\n      <td>Fits true to size, take your normal size\\nCut ...</td>\n      <td>'7':15 '93':13 'beig':7 'camisol':6A 'clean':1...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>beige</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>AMI Paris</td>\n      <td>Postcard Patch Hoodie</td>\n      <td>casual cotton-blend hoodie with an embossed la...</td>\n      <td>themensstore apparel sweatshirtshoodies18q1</td>\n      <td>https://www.saksfifthavenue.com/ami-paris-post...</td>\n      <td>Attached drawstring hood\\nLong sleeves\\nPullov...</td>\n      <td>'ami':1A,15 'blend':9 'casual':6 'chest':21 'c...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Alexander Wang</td>\n      <td>Layered velvet mini dress</td>\n      <td>black velvet concealed hook and zip fastening ...</td>\n      <td>clothing dresses mini</td>\n      <td>https://www.net-a-porter.com/us/en/product/120...</td>\n      <td>Fits true to size, take your normal size \\nDes...</td>\n      <td>'100':21 '35':18 '65':16 'alexand':1A 'back':1...</td>\n      <td>1</td>\n      <td>One Piece</td>\n      <td>multi</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>J.Crew</td>\n      <td>Wide leather belt</td>\n      <td>the ideal way to add definition to your favori...</td>\n      <td>belts</td>\n      <td>https://www.jcrew.com/p/womens_category/belts/...</td>\n      <td>NaN</td>\n      <td>'add':9 'belt':4A,17 'better':27 'custom':19 '...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>J.Crew</td>\n      <td>Faux-leather pleated midi skirt</td>\n      <td>with accordion pleats and a flattering midi le...</td>\n      <td>skirts</td>\n      <td>https://www.jcrew.com/p/womens_category/skirts...</td>\n      <td>NaN</td>\n      <td>'accordion':9 'faux':3A,18 'faux-leath':2A,17 ...</td>\n      <td>1</td>\n      <td>bottom</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Alexander Wang</td>\n      <td>Parker logo-embellished snake-effect leather a...</td>\n      <td>heel measures approximately 75mm/ 3 inches sna...</td>\n      <td>shoes boots ankle</td>\n      <td>https://www.net-a-porter.com/us/en/product/115...</td>\n      <td>Fits true to size, take your normal size \\nIta...</td>\n      <td>'3':17 '75mm':16 'alexand':1A 'along':26 'ankl...</td>\n      <td>0</td>\n      <td>Shoe</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Frame</td>\n      <td>Le Garcon--NOIR</td>\n      <td>a sophisticated boyfriend jean with a tailored...</td>\n      <td>jeans</td>\n      <td>https://frame-store.com/products/le-garcon-noir</td>\n      <td>NaN</td>\n      <td>'black':18 'boyfriend':7 'craft':15 'denim':19...</td>\n      <td>0</td>\n      <td>bottom</td>\n      <td>multi</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>TDE</td>\n      <td>Leather iPhone X Case</td>\n      <td>essential phone case cut from rich saffiano le...</td>\n      <td>jewelryaccessories accessories mobiletechcases...</td>\n      <td>https://www.saksfifthavenue.com/tde-leather-ip...</td>\n      <td>Dust bag included\\nRubber lining\\nSaffiano lea...</td>\n      <td>'case':5A,8 'cut':9 'essenti':6 'iphon':3A 'le...</td>\n      <td>0</td>\n      <td>Handbag</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Hatley</td>\n      <td>Little Kid's &amp; Kid's Splash Jacket</td>\n      <td>colorful raincoat with cozy lining keeps them ...</td>\n      <td>justkids boys220 toddlerboys24 outerwear justk...</td>\n      <td>https://www.saksfifthavenue.com/hatley-little-...</td>\n      <td>Attached hood\\nLong sleeves\\nSnap button front...</td>\n      <td>'color':9 'cozi':12 'hatley':1A 'jacket':8A 'k...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Tom Ford</td>\n      <td>Miranda 68MM Oversized Round Sunglasses</td>\n      <td>oversized crossover metal frame with open temp...</td>\n      <td>jewelryaccessories sunglassesreaders oversized...</td>\n      <td>https://www.saksfifthavenue.com/tom-ford-miran...</td>\n      <td>100% UV protection\\nGradient brown lenses\\nAdj...</td>\n      <td>'68mm':4A 'avail':18 'brown':24 'crossov':9 'f...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>multi</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Montblanc</td>\n      <td>Horseshoe Buckle Suede Belt</td>\n      <td>horse-shoe shaped palladium-coated pin buckle ...</td>\n      <td>themensstore accessories belts</td>\n      <td>https://www.saksfifthavenue.com/montblanc-hors...</td>\n      <td>Self-adjustable\\nSilvertone hardware\\nLeather\\...</td>\n      <td>'antiqu':16 'belt':5A 'buckl':3A,14 'coat':12 ...</td>\n      <td>0</td>\n      <td>Shoe</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Theory</td>\n      <td>Silk-crepe midi dress</td>\n      <td>black silk-crepe concealed zip fastening along...</td>\n      <td>clothing dresses midi</td>\n      <td>https://www.net-a-porter.com/us/en/product/120...</td>\n      <td>Fits true to size, take your normal size\\nCut ...</td>\n      <td>'100':16,24 '35':21 '65':19 'along':14 'back':...</td>\n      <td>1</td>\n      <td>One Piece</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>J.Crew</td>\n      <td>Tall stretch Secret Wash shirt in square conne...</td>\n      <td>meet the pinnacle of shirt engineering a custo...</td>\n      <td>shirts</td>\n      <td>https://www.jcrew.com/p/mens_category/shirts/t...</td>\n      <td>NaN</td>\n      <td>'2005':22 'achiev':87 'ad':64 'better':48 'bro...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>J.Crew</td>\n      <td>Loeffler RandallÂ® Emilia pleated knot slide s...</td>\n      <td>step up your sandal game with this best seller...</td>\n      <td>shoes</td>\n      <td>https://www.jcrew.com/p/womens_category/shoes/...</td>\n      <td>NaN</td>\n      <td>'accessori':25 'action':43 'aka':37 'base':21 ...</td>\n      <td>1</td>\n      <td>Shoe</td>\n      <td>gold</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# final output\n",
    "\n",
    "catalog = catalog.drop(columns = [\n",
    "    'name_cate',\n",
    "    'name_cate_des'\n",
    "])\n",
    "\n",
    "catalog.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get features of names \n",
    "\n",
    "# names = catalog.name\n",
    "\n",
    "# stemmer = nltk.stem.porter.PorterStemmer()\n",
    "# names = reviews.apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: [stemmer.stem(y) for y in x]).apply(lambda x: ' '.join(x))\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(names) \n",
    "# X = X.toarray()\n",
    "\n",
    "# corpus_df = pd.DataFrame(X, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# # iterate through the Pandas dataframe, and drop the columns that reflect stopwords:\n",
    "# original_columns = corpus_df.columns # get existing columns\n",
    "\n",
    "# to_drop_columns = set(original_columns).intersection(set(list_stopwords)) # get the list of words to drop\n",
    "\n",
    "# # before drop stopwords\n",
    "# print(f\"Dataframe shape was {corpus_df.shape}\")\n",
    "\n",
    "# # after drop stopwords \n",
    "# corpus_df.drop(columns=to_drop_columns, inplace=True)\n",
    "# print(f\"Dataframe shape is now {corpus_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}