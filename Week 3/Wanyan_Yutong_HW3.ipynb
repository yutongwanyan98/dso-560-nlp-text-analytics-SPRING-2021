{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3\n",
    "\n",
    "Submit via Slack. Due on Tuesday, April 13th, 2020, 6:29pm PST. You may work with one other person.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "You are an analyst working at McDonalds as a store operations analyst, and charged with identifying areas for improvement for each franchise. Several metropolitan locations have been suffering recently from lower reviews.\n",
    "\n",
    "Using the **mcdonalds-yelp-negative-reviews.csv** dataset, clean and parse the text reviews. Explain the decisions you make:\n",
    "- why remove/keep stopwords?\n",
    "- which stopwords to remove?\n",
    "- stemming versus lemmatization?\n",
    "- regex cleaning and substitution?\n",
    "- adding in custom stopwords?\n",
    "- what `n` for your `n-grams`?\n",
    "- which words to collocate together?\n",
    "\n",
    "Finally, generate a TF-IDF report that either **visualizes** or explains for a business (non-technical) stakeholder:\n",
    "* the features your analysis showed that customers cited as reasons for a poor review\n",
    "* the most common issues identified from your analysis that generated customer dissatisfaction.\n",
    "\n",
    "Explain to what degree the TF-IDF findings make sense - what are its limitations?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/yutongwanyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/yutongwanyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/yutongwanyan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import time\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt') # A popular NLTK sentence tokenizer\n",
    "nltk.download('stopwords') # library of common English stopwords\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    _unit_id     city                                             review\n",
       "0  679455653  Atlanta  I'm not a huge mcds lover, but I've been to be...\n",
       "1  679455654  Atlanta  Terrible customer service. I came in at 9:30pm...\n",
       "2  679455655  Atlanta  First they \"lost\" my order, actually they gave...\n",
       "3  679455656  Atlanta  I see I'm not the only one giving 1 star. Only...\n",
       "4  679455657  Atlanta  Well, it's McDonald's, so you know what the fo..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_unit_id</th>\n      <th>city</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>679455653</td>\n      <td>Atlanta</td>\n      <td>I'm not a huge mcds lover, but I've been to be...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>679455654</td>\n      <td>Atlanta</td>\n      <td>Terrible customer service. I came in at 9:30pm...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>679455655</td>\n      <td>Atlanta</td>\n      <td>First they \"lost\" my order, actually they gave...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>679455656</td>\n      <td>Atlanta</td>\n      <td>I see I'm not the only one giving 1 star. Only...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>679455657</td>\n      <td>Atlanta</td>\n      <td>Well, it's McDonald's, so you know what the fo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# read the file \n",
    "yelp = pd.read_csv('mcdonalds-yelp-negative-reviews.csv', encoding='latin-1')\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the review \n",
    "reviews = yelp['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ma']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# stopwords.words('english')\n",
    "list_stopwords = stopwords.words('english')\n",
    "for i in list_stopwords:\n",
    "    if \"n't\" in i:\n",
    "        list_stopwords.remove(i)\n",
    "for i in ('don ain aren couldn didn doesn hadn hasn haven isn mightn mustn needn shan shouldn wasn weren won wouldn').split(' '):\n",
    "    if i in list_stopwords:\n",
    "        list_stopwords.remove(i)\n",
    "\n",
    "print(list_stopwords) \n",
    "\n",
    "# I removed stop words that related to xx-not as they express denial/negative feelings in the reviews. As we're trying to understand why McDonald is doing poorly in certain aspects, we should remove them out of stopword list to make sure we don't miss some negative reviews \n",
    "\n",
    "# The stopwords I keep are mostly pronouce and frequently used stopwords. They do not provide us significant information (unless we have a clear goal of study like if poor employee performance relates to gender etc; in that case we want to remove pronounces from this list as well)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       I 'm not a huge mcd lover , but I 've been to ...\n",
       "1       terribl custom servic . I came in at 9:30pm an...\n",
       "2       first they `` lost '' my order , actual they g...\n",
       "3       I see I 'm not the onli one give 1 star . onli...\n",
       "4       well , it 's mcdonald 's , so you know what th...\n",
       "                              ...                        \n",
       "1520    I enjoy the part where I repeatedli ask if I h...\n",
       "1521    worst mcdonald I 've been in in a long time ! ...\n",
       "1522    when I am realli crave for mcdonald 's , thi s...\n",
       "1523    two point right out of the gate : 1 . thuggeri...\n",
       "1524    I want to grab breakfast one morn befor work s...\n",
       "Name: review, Length: 1525, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "reviews = reviews.apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: [stemmer.stem(y) for y in x]).apply(lambda x: ' '.join(x))\n",
    "reviews\n",
    "\n",
    "# Similar in HW2, I decided to use stemming because it's \n",
    "# (1) working fast on a 1500+ rows series and \n",
    "# (2) I prefer to take more aggresive approach to reduce final dimensionalty of words or n-gram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More latex cleaning (improved from hw 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       I 'm not a huge mcd lover , but I 've been to ...\n",
       "1       terribl custom servic . I came in at 9:30pm an...\n",
       "2       first they `` lost '' my order , actual they g...\n",
       "3       I see I 'm not the onli one give 1 star . onli...\n",
       "4       well , it 's mcd 's , so you know what the foo...\n",
       "                              ...                        \n",
       "1520    I enjoy the part where I repeatedli ask if I h...\n",
       "1521    worst mcd I 've been in in a long time ! dirt ...\n",
       "1522    when I am realli crave for mcd 's , thi seem t...\n",
       "1523    two point right out of the gate : 1 . thuggeri...\n",
       "1524    I want to grab breakfast one morn befor work s...\n",
       "Name: review, Length: 1525, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# more latex cleaning (improved from hw 2)\n",
    "\n",
    "pattern_dict = {\n",
    "    r'(\\w+burger\\b)':'burger',\n",
    "    r'(\\bbarbe+\\w+|bbq)':'barbeque',\n",
    "    r'(\\bchoco+\\w+\\b)':'chocolate',\n",
    "    r'(\\bcoffe+\\w+)':\"coffee\",\n",
    "    r'(\\bfrap+\\w+)':'frappuccino',\n",
    "    r'(\\bdirt+\\w+)':'dirty',\n",
    "    r'(\\bdisa+\\w+t)':'disappoint',\n",
    "    r'(\\bhm|hmm+\\w)':'hmm',\n",
    "    r'(\\blettuce+\\w)':'lettuce',\n",
    "    r'(\\blo+\\w+g)':'long',\n",
    "    r'(\\blow|low+\\w)':'low',\n",
    "    r'(\\bmcdo+\\w+|mcd+\\w\\b)':'mcd',\n",
    "    r'(\\bmcchichen|mcchicken)':'mcchicken',\n",
    "    r'(\\bm+\\w+m|mm)':'m'\n",
    "} # again, these are some examples for regex cleaning; most of them I choose here are food names and stop words we can add later into the stopword list\n",
    "\n",
    "for i in pattern_dict:\n",
    "    reviews = reviews.apply(lambda x: re.sub(i, pattern_dict[i], x))\n",
    "reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of add stop words we created from regex cleaninig\n",
    "\n",
    "list_stopwords = list_stopwords + [\n",
    "    'hmm',\n",
    "    'get',\n",
    "    'thi',\n",
    "    'look',\n",
    "    'ever'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorize the Documents\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(reviews) \n",
    "X = X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataframe shape was (1525, 6383)\nDataframe shape is now (1525, 6269)\n"
     ]
    }
   ],
   "source": [
    "corpus_df = pd.DataFrame(X, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# iterate through the Pandas dataframe, and drop the columns that reflect stopwords:\n",
    "original_columns = corpus_df.columns # get existing columns\n",
    "\n",
    "to_drop_columns = set(original_columns).intersection(set(list_stopwords)) # get the list of words to drop\n",
    "\n",
    "# before drop stopwords\n",
    "print(f\"Dataframe shape was {corpus_df.shape}\")\n",
    "\n",
    "# after drop stopwords \n",
    "corpus_df.drop(columns=to_drop_columns, inplace=True)\n",
    "print(f\"Dataframe shape is now {corpus_df.shape}\")\n",
    "\n",
    "# NOW if compared to the same step of hw2, the number of columns (after removing stop words) are reduced from 6327 to 6269\n",
    "# it shows that both regex cleaning and stopwords manipulation have worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report tf_idf, using bi-gram\n",
    "\n",
    "# first define re-usable function\n",
    "\n",
    "def get_tf_idf(documents, ngram_range=(1,1), stop_word_true = True, stopword_list = list_stopwords):\n",
    "    '''\n",
    "    documents: a list of documents, as the corpus\n",
    "    ngram_range: a tuple for n-gram size\n",
    "    stop_word_true: if remove stopwords \n",
    "    stopword_list: a list of stopwords defined by user; by default list_stopwords\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    corpus = documents\n",
    "\n",
    "    if stop_word_true == True:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range,\n",
    "                                    token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                    # max_df=0.4, \n",
    "                                    stop_words=stopword_list\n",
    "                                    )\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range,\n",
    "                                token_pattern=r'\\b[a-zA-Z]{3,}\\b'\n",
    "                                )\n",
    "\n",
    "                                \n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "\n",
    "    tf_idf = tf_idf.sum(axis=1)\n",
    "    score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "    score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of word combination/collocations: 49843\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    score\n",
       "drive thru      24.967784\n",
       "fast food       10.857615\n",
       "worst mcd       10.079700\n",
       "custom servic    9.635739\n",
       "ice cream        6.737402\n",
       "order wrong      6.484587\n",
       "big mac          5.701065\n",
       "take order       5.543923\n",
       "wait minut       5.466364\n",
       "everi time       5.107380\n",
       "order right      4.992328\n",
       "place order      4.397336\n",
       "mess order       4.385047\n",
       "chicken nugget   4.358886\n",
       "late night       4.257971\n",
       "ice coffe        3.981700\n",
       "park lot         3.851295\n",
       "french fri       3.671405\n",
       "tast like        3.658143\n",
       "egg muffin       3.564226"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drive thru</th>\n      <td>24.967784</td>\n    </tr>\n    <tr>\n      <th>fast food</th>\n      <td>10.857615</td>\n    </tr>\n    <tr>\n      <th>worst mcd</th>\n      <td>10.079700</td>\n    </tr>\n    <tr>\n      <th>custom servic</th>\n      <td>9.635739</td>\n    </tr>\n    <tr>\n      <th>ice cream</th>\n      <td>6.737402</td>\n    </tr>\n    <tr>\n      <th>order wrong</th>\n      <td>6.484587</td>\n    </tr>\n    <tr>\n      <th>big mac</th>\n      <td>5.701065</td>\n    </tr>\n    <tr>\n      <th>take order</th>\n      <td>5.543923</td>\n    </tr>\n    <tr>\n      <th>wait minut</th>\n      <td>5.466364</td>\n    </tr>\n    <tr>\n      <th>everi time</th>\n      <td>5.107380</td>\n    </tr>\n    <tr>\n      <th>order right</th>\n      <td>4.992328</td>\n    </tr>\n    <tr>\n      <th>place order</th>\n      <td>4.397336</td>\n    </tr>\n    <tr>\n      <th>mess order</th>\n      <td>4.385047</td>\n    </tr>\n    <tr>\n      <th>chicken nugget</th>\n      <td>4.358886</td>\n    </tr>\n    <tr>\n      <th>late night</th>\n      <td>4.257971</td>\n    </tr>\n    <tr>\n      <th>ice coffe</th>\n      <td>3.981700</td>\n    </tr>\n    <tr>\n      <th>park lot</th>\n      <td>3.851295</td>\n    </tr>\n    <tr>\n      <th>french fri</th>\n      <td>3.671405</td>\n    </tr>\n    <tr>\n      <th>tast like</th>\n      <td>3.658143</td>\n    </tr>\n    <tr>\n      <th>egg muffin</th>\n      <td>3.564226</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# create corpus \n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in reviews:\n",
    "    corpus.append(i)\n",
    "\n",
    "# report tf_idf\n",
    "tf_idf_score = get_tf_idf(corpus, ngram_range=(2,2), stop_word_true = True)\n",
    "print(f'Number of word combination/collocations: {tf_idf_score.shape[0]}')\n",
    "tf_idf_score[:20]\n",
    "\n",
    "# if we choose 2 for n-gram, we get some words collocated together that are frequently used. Show top 20 as examples.\n",
    "# some word combinations make sense, like drive thru, fast food, big mac, ice cream etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of word combination/collocations: 64816\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      score\n",
       "drive thru window  2.447772\n",
       "went drive thru    2.441666\n",
       "drive thru order   2.390912\n",
       "got order wrong    2.323411\n",
       "drive thru line    2.322075\n",
       "fast food place    1.908174\n",
       "everi singl time   1.778436\n",
       "never order right  1.599128\n",
       "ice cream cone     1.553606\n",
       "ice cream machin   1.533518"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drive thru window</th>\n      <td>2.447772</td>\n    </tr>\n    <tr>\n      <th>went drive thru</th>\n      <td>2.441666</td>\n    </tr>\n    <tr>\n      <th>drive thru order</th>\n      <td>2.390912</td>\n    </tr>\n    <tr>\n      <th>got order wrong</th>\n      <td>2.323411</td>\n    </tr>\n    <tr>\n      <th>drive thru line</th>\n      <td>2.322075</td>\n    </tr>\n    <tr>\n      <th>fast food place</th>\n      <td>1.908174</td>\n    </tr>\n    <tr>\n      <th>everi singl time</th>\n      <td>1.778436</td>\n    </tr>\n    <tr>\n      <th>never order right</th>\n      <td>1.599128</td>\n    </tr>\n    <tr>\n      <th>ice cream cone</th>\n      <td>1.553606</td>\n    </tr>\n    <tr>\n      <th>ice cream machin</th>\n      <td>1.533518</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# if we choose n = 3\n",
    "\n",
    "tf_idf_score = get_tf_idf(corpus, ngram_range=(3,3), stop_word_true = True)\n",
    "print(f'Number of word combination/collocations: {tf_idf_score.shape[0]}')\n",
    "tf_idf_score[:10]\n",
    "\n",
    "# from the top results, we can see first 3 combinations are all about drive through; this indicates that n = 2 is more efficient than n = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Attribution (Feature Engineering and Regex Practice)\n",
    "\n",
    "Download the [dataset](https://dso-560-nlp-text-analytics.s3.amazonaws.com/truncated_catalog.csv) from the class S3 bucket (`dso560-nlp-text-analytics`).\n",
    "\n",
    "In preparation for the group project, our client company has provided a dataset of women's clothing products they are considering cataloging. \n",
    "\n",
    "1. Filter for only **women's clothing items**.\n",
    "\n",
    "2. For each clothing item:\n",
    "\n",
    "* Identify its **category**:\n",
    "```\n",
    "Bottom\n",
    "One Piece\n",
    "Shoe\n",
    "Handbag\n",
    "Scarf\n",
    "```\n",
    "* Identify its **color**:\n",
    "```\n",
    "Beige\n",
    "Black\n",
    "Blue\n",
    "Brown\n",
    "Burgundy\n",
    "Gold\n",
    "Gray\n",
    "Green\n",
    "Multi \n",
    "Navy\n",
    "Neutral\n",
    "Orange\n",
    "Pinks\n",
    "Purple\n",
    "Red\n",
    "Silver\n",
    "Teal\n",
    "White\n",
    "Yellow\n",
    "```\n",
    "\n",
    "Your output will be the same dataset, except with **3 additional fields**:\n",
    "* `is_womens_clothing`\n",
    "* `product_category`\n",
    "* `colors`\n",
    "\n",
    "`colors` should be a list of colors, since it is possible for a piece of clothing to have multiple colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              ï»¿brand                                               name  \\\n",
       "0                 FILA                          Original Fitness Sneakers   \n",
       "1               CHANEL                                                HAT   \n",
       "2                Frame                             Petit Oval Buckle Belt   \n",
       "3  Lilly Pulitzer Kids  Little Gir's & Girl's Ariana One-Piece UPF 50+...   \n",
       "4          Kissy Kissy  Baby Girl's Endearing Elephants Pima Cotton Co...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Vintage Fitness leather sneakers with logo pri...   \n",
       "1                                                NaN   \n",
       "2  A Timeless Leather Belt Crafted From Smooth Co...   \n",
       "3  Pretty ruffle sleeves and trim elevate essenti...   \n",
       "4  Versatile convertible gown with elephant applique   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                 TheMensStore/Shoes/Sneakers/LowTop   \n",
       "1                                            Unknown   \n",
       "2                                        Accessories   \n",
       "3  JustKids/Girls214/Girls/SwimwearCoverups,JustK...   \n",
       "4  JustKids/Baby024months/InfantGirls/FootiesRompers   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://www.saksfifthavenue.com/fila-original-...   \n",
       "1  https://www.saksfifthavenue.com/chanel-hat/pro...   \n",
       "2  https://frame-store.com/products/petit-oval-bu...   \n",
       "3  https://www.saksfifthavenue.com/lilly-pulitzer...   \n",
       "4  https://www.saksfifthavenue.com/kissy-kissy-ba...   \n",
       "\n",
       "                                             details  \\\n",
       "0  Leather/synthetic upper\\nLace-up closure\\nText...   \n",
       "1                                  WOOL TWEED & FELT   \n",
       "2                                                NaN   \n",
       "3  Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...   \n",
       "4  V-neckline\\nLong sleeves\\nFront snap closure\\n...   \n",
       "\n",
       "                                                 tsv  \n",
       "0  'design':12 'fila':1A 'fit':3A,6 'leather':7 '...  \n",
       "1                               'chanel':1A 'hat':2A  \n",
       "2  'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...  \n",
       "3  '50':14A 'allov':28 'ariana':9A 'color':27 'el...  \n",
       "4  'appliqu':17 'babi':3A 'convert':10A,13 'cotto...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ï»¿brand</th>\n      <th>name</th>\n      <th>description</th>\n      <th>brand_category</th>\n      <th>brand_canonical_url</th>\n      <th>details</th>\n      <th>tsv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FILA</td>\n      <td>Original Fitness Sneakers</td>\n      <td>Vintage Fitness leather sneakers with logo pri...</td>\n      <td>TheMensStore/Shoes/Sneakers/LowTop</td>\n      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n      <td>Leather/synthetic upper\\nLace-up closure\\nText...</td>\n      <td>'design':12 'fila':1A 'fit':3A,6 'leather':7 '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHANEL</td>\n      <td>HAT</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n      <td>WOOL TWEED &amp; FELT</td>\n      <td>'chanel':1A 'hat':2A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Frame</td>\n      <td>Petit Oval Buckle Belt</td>\n      <td>A Timeless Leather Belt Crafted From Smooth Co...</td>\n      <td>Accessories</td>\n      <td>https://frame-store.com/products/petit-oval-bu...</td>\n      <td>NaN</td>\n      <td>'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lilly Pulitzer Kids</td>\n      <td>Little Gir's &amp; Girl's Ariana One-Piece UPF 50+...</td>\n      <td>Pretty ruffle sleeves and trim elevate essenti...</td>\n      <td>JustKids/Girls214/Girls/SwimwearCoverups,JustK...</td>\n      <td>https://www.saksfifthavenue.com/lilly-pulitzer...</td>\n      <td>Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...</td>\n      <td>'50':14A 'allov':28 'ariana':9A 'color':27 'el...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kissy Kissy</td>\n      <td>Baby Girl's Endearing Elephants Pima Cotton Co...</td>\n      <td>Versatile convertible gown with elephant applique</td>\n      <td>JustKids/Baby024months/InfantGirls/FootiesRompers</td>\n      <td>https://www.saksfifthavenue.com/kissy-kissy-ba...</td>\n      <td>V-neckline\\nLong sleeves\\nFront snap closure\\n...</td>\n      <td>'appliqu':17 'babi':3A 'convert':10A,13 'cotto...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "catalog = pd.read_csv('truncated_catalog.csv', encoding='latin-1')\n",
    "catalog.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              ï»¿brand                                               name  \\\n",
       "0                 FILA                          Original Fitness Sneakers   \n",
       "1               CHANEL                                                HAT   \n",
       "2                Frame                             Petit Oval Buckle Belt   \n",
       "3  Lilly Pulitzer Kids  Little Gir's & Girl's Ariana One-Piece UPF 50+...   \n",
       "4          Kissy Kissy  Baby Girl's Endearing Elephants Pima Cotton Co...   \n",
       "5              Jocelyn  Savage Love Texty Time Leopard-Print Rabbit Fu...   \n",
       "6               Theory                         Teah stretch-silk camisole   \n",
       "7            AMI Paris                              Postcard Patch Hoodie   \n",
       "8       Alexander Wang                          Layered velvet mini dress   \n",
       "9               J.Crew                                  Wide leather belt   \n",
       "\n",
       "                                         description  \\\n",
       "0  Vintage Fitness leather sneakers with logo pri...   \n",
       "1                                                NaN   \n",
       "2  A Timeless Leather Belt Crafted From Smooth Co...   \n",
       "3  Pretty ruffle sleeves and trim elevate essenti...   \n",
       "4  Versatile convertible gown with elephant applique   \n",
       "5  From the Savage Love Collection. Fingerless kn...   \n",
       "6  Beige stretch-silk Slips on 93% silk, 7% spand...   \n",
       "7  Casual cotton-blend hoodie with an embossed la...   \n",
       "8  Black velvet Concealed hook and zip fastening ...   \n",
       "9  The ideal way to add definition to your favori...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                 TheMensStore/Shoes/Sneakers/LowTop   \n",
       "1                                            Unknown   \n",
       "2                                        Accessories   \n",
       "3  JustKids/Girls214/Girls/SwimwearCoverups,JustK...   \n",
       "4  JustKids/Baby024months/InfantGirls/FootiesRompers   \n",
       "5              JewelryAccessories/Accessories/Gloves   \n",
       "6                  Clothing / Tops / Tanks and Camis   \n",
       "7        TheMensStore/Apparel/SweatshirtsHoodies18Q1   \n",
       "8                          Clothing / Dresses / Mini   \n",
       "9                                              belts   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://www.saksfifthavenue.com/fila-original-...   \n",
       "1  https://www.saksfifthavenue.com/chanel-hat/pro...   \n",
       "2  https://frame-store.com/products/petit-oval-bu...   \n",
       "3  https://www.saksfifthavenue.com/lilly-pulitzer...   \n",
       "4  https://www.saksfifthavenue.com/kissy-kissy-ba...   \n",
       "5  https://www.saksfifthavenue.com/jocelyn-savage...   \n",
       "6  https://www.net-a-porter.com/us/en/product/119...   \n",
       "7  https://www.saksfifthavenue.com/ami-paris-post...   \n",
       "8  https://www.net-a-porter.com/us/en/product/120...   \n",
       "9  https://www.jcrew.com/p/womens_category/belts/...   \n",
       "\n",
       "                                             details  \\\n",
       "0  Leather/synthetic upper\\nLace-up closure\\nText...   \n",
       "1                                  WOOL TWEED & FELT   \n",
       "2                                                NaN   \n",
       "3  Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...   \n",
       "4  V-neckline\\nLong sleeves\\nFront snap closure\\n...   \n",
       "5  Acrylic/wool\\nFur type: Dyed rabbit\\nFur origi...   \n",
       "6  Fits true to size, take your normal size\\nCut ...   \n",
       "7  Attached drawstring hood\\nLong sleeves\\nPullov...   \n",
       "8  Fits true to size, take your normal size \\nDes...   \n",
       "9                                                NaN   \n",
       "\n",
       "                                                 tsv  \n",
       "0  'design':12 'fila':1A 'fit':3A,6 'leather':7 '...  \n",
       "1                               'chanel':1A 'hat':2A  \n",
       "2  'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...  \n",
       "3  '50':14A 'allov':28 'ariana':9A 'color':27 'el...  \n",
       "4  'appliqu':17 'babi':3A 'convert':10A,13 'cotto...  \n",
       "5  'ad':29 'collect':16 'craft':20 'fingerless':1...  \n",
       "6  '7':15 '93':13 'beig':7 'camisol':6A 'clean':1...  \n",
       "7  'ami':1A,15 'blend':9 'casual':6 'chest':21 'c...  \n",
       "8  '100':21 '35':18 '65':16 'alexand':1A 'back':1...  \n",
       "9  'add':9 'belt':4A,17 'better':27 'custom':19 '...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ï»¿brand</th>\n      <th>name</th>\n      <th>description</th>\n      <th>brand_category</th>\n      <th>brand_canonical_url</th>\n      <th>details</th>\n      <th>tsv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FILA</td>\n      <td>Original Fitness Sneakers</td>\n      <td>Vintage Fitness leather sneakers with logo pri...</td>\n      <td>TheMensStore/Shoes/Sneakers/LowTop</td>\n      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n      <td>Leather/synthetic upper\\nLace-up closure\\nText...</td>\n      <td>'design':12 'fila':1A 'fit':3A,6 'leather':7 '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHANEL</td>\n      <td>HAT</td>\n      <td>NaN</td>\n      <td>Unknown</td>\n      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n      <td>WOOL TWEED &amp; FELT</td>\n      <td>'chanel':1A 'hat':2A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Frame</td>\n      <td>Petit Oval Buckle Belt</td>\n      <td>A Timeless Leather Belt Crafted From Smooth Co...</td>\n      <td>Accessories</td>\n      <td>https://frame-store.com/products/petit-oval-bu...</td>\n      <td>NaN</td>\n      <td>'belt':5A,9 'buckl':4A,21 'cowhid':13 'craft':...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lilly Pulitzer Kids</td>\n      <td>Little Gir's &amp; Girl's Ariana One-Piece UPF 50+...</td>\n      <td>Pretty ruffle sleeves and trim elevate essenti...</td>\n      <td>JustKids/Girls214/Girls/SwimwearCoverups,JustK...</td>\n      <td>https://www.saksfifthavenue.com/lilly-pulitzer...</td>\n      <td>Scoopneck\\nAdjustable straps\\nFlutter sleeves\\...</td>\n      <td>'50':14A 'allov':28 'ariana':9A 'color':27 'el...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kissy Kissy</td>\n      <td>Baby Girl's Endearing Elephants Pima Cotton Co...</td>\n      <td>Versatile convertible gown with elephant applique</td>\n      <td>JustKids/Baby024months/InfantGirls/FootiesRompers</td>\n      <td>https://www.saksfifthavenue.com/kissy-kissy-ba...</td>\n      <td>V-neckline\\nLong sleeves\\nFront snap closure\\n...</td>\n      <td>'appliqu':17 'babi':3A 'convert':10A,13 'cotto...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jocelyn</td>\n      <td>Savage Love Texty Time Leopard-Print Rabbit Fu...</td>\n      <td>From the Savage Love Collection. Fingerless kn...</td>\n      <td>JewelryAccessories/Accessories/Gloves</td>\n      <td>https://www.saksfifthavenue.com/jocelyn-savage...</td>\n      <td>Acrylic/wool\\nFur type: Dyed rabbit\\nFur origi...</td>\n      <td>'ad':29 'collect':16 'craft':20 'fingerless':1...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Theory</td>\n      <td>Teah stretch-silk camisole</td>\n      <td>Beige stretch-silk Slips on 93% silk, 7% spand...</td>\n      <td>Clothing / Tops / Tanks and Camis</td>\n      <td>https://www.net-a-porter.com/us/en/product/119...</td>\n      <td>Fits true to size, take your normal size\\nCut ...</td>\n      <td>'7':15 '93':13 'beig':7 'camisol':6A 'clean':1...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>AMI Paris</td>\n      <td>Postcard Patch Hoodie</td>\n      <td>Casual cotton-blend hoodie with an embossed la...</td>\n      <td>TheMensStore/Apparel/SweatshirtsHoodies18Q1</td>\n      <td>https://www.saksfifthavenue.com/ami-paris-post...</td>\n      <td>Attached drawstring hood\\nLong sleeves\\nPullov...</td>\n      <td>'ami':1A,15 'blend':9 'casual':6 'chest':21 'c...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Alexander Wang</td>\n      <td>Layered velvet mini dress</td>\n      <td>Black velvet Concealed hook and zip fastening ...</td>\n      <td>Clothing / Dresses / Mini</td>\n      <td>https://www.net-a-porter.com/us/en/product/120...</td>\n      <td>Fits true to size, take your normal size \\nDes...</td>\n      <td>'100':21 '35':18 '65':16 'alexand':1A 'back':1...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>J.Crew</td>\n      <td>Wide leather belt</td>\n      <td>The ideal way to add definition to your favori...</td>\n      <td>belts</td>\n      <td>https://www.jcrew.com/p/womens_category/belts/...</td>\n      <td>NaN</td>\n      <td>'add':9 'belt':4A,17 'better':27 'custom':19 '...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "catalog.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}